{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autocorelation_00_kurtosis</th>\n",
       "      <th>autocorelation_00_max</th>\n",
       "      <th>autocorelation_00_mean</th>\n",
       "      <th>autocorelation_00_median</th>\n",
       "      <th>autocorelation_00_min</th>\n",
       "      <th>autocorelation_00_skew</th>\n",
       "      <th>autocorelation_00_std</th>\n",
       "      <th>autocorelation_00_sum</th>\n",
       "      <th>chroma_cens_00_kurtosis</th>\n",
       "      <th>chroma_cens_00_max</th>\n",
       "      <th>...</th>\n",
       "      <th>dtempo_changes</th>\n",
       "      <th>onset_count</th>\n",
       "      <th>low_energy_rate</th>\n",
       "      <th>harmonic_to_noise_rate</th>\n",
       "      <th>dynamic_range</th>\n",
       "      <th>swing_ratio</th>\n",
       "      <th>syncopation</th>\n",
       "      <th>roughness</th>\n",
       "      <th>warmth</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.768500</td>\n",
       "      <td>12364.4260</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>-2.887901</td>\n",
       "      <td>-1593.9122</td>\n",
       "      <td>170.368180</td>\n",
       "      <td>3.016389</td>\n",
       "      <td>7.194268e+03</td>\n",
       "      <td>1.221379</td>\n",
       "      <td>0.379768</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-14.303785</td>\n",
       "      <td>0.218490</td>\n",
       "      <td>1.109646</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>191.356035</td>\n",
       "      <td>0.701712</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.686200</td>\n",
       "      <td>2798.3555</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.398690</td>\n",
       "      <td>-1224.2454</td>\n",
       "      <td>88.129974</td>\n",
       "      <td>0.790848</td>\n",
       "      <td>1.422519e+03</td>\n",
       "      <td>-0.882889</td>\n",
       "      <td>0.659657</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.258749</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>1.139929</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>57.557036</td>\n",
       "      <td>0.605086</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.787950</td>\n",
       "      <td>65289.0160</td>\n",
       "      <td>0.065771</td>\n",
       "      <td>-5.728954</td>\n",
       "      <td>-35123.4340</td>\n",
       "      <td>4982.006300</td>\n",
       "      <td>0.158547</td>\n",
       "      <td>4.347565e+04</td>\n",
       "      <td>-0.937324</td>\n",
       "      <td>0.564553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.661439</td>\n",
       "      <td>1.154552</td>\n",
       "      <td>0.112588</td>\n",
       "      <td>1374.684072</td>\n",
       "      <td>0.611777</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.609666</td>\n",
       "      <td>60351.8500</td>\n",
       "      <td>1.028323</td>\n",
       "      <td>-2.132175</td>\n",
       "      <td>-29979.5370</td>\n",
       "      <td>5215.574700</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>6.797144e+05</td>\n",
       "      <td>-0.495610</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>211</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.258297</td>\n",
       "      <td>0.504590</td>\n",
       "      <td>1.079204</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>2111.869221</td>\n",
       "      <td>0.401475</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.699970</td>\n",
       "      <td>22080.5940</td>\n",
       "      <td>74.396010</td>\n",
       "      <td>34.283890</td>\n",
       "      <td>-5716.5230</td>\n",
       "      <td>437.943730</td>\n",
       "      <td>4.025559</td>\n",
       "      <td>4.917499e+07</td>\n",
       "      <td>-0.863015</td>\n",
       "      <td>0.472208</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.470797</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>1.155421</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>284.493888</td>\n",
       "      <td>0.461459</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   autocorelation_00_kurtosis  autocorelation_00_max  autocorelation_00_mean  \\\n",
       "0                  141.768500             12364.4260                0.010876   \n",
       "1                   31.686200              2798.3555                0.002150   \n",
       "2                   11.787950             65289.0160                0.065771   \n",
       "3                    4.609666             60351.8500                1.028323   \n",
       "4                  113.699970             22080.5940               74.396010   \n",
       "\n",
       "   autocorelation_00_median  autocorelation_00_min  autocorelation_00_skew  \\\n",
       "0                 -2.887901             -1593.9122              170.368180   \n",
       "1                 -0.398690             -1224.2454               88.129974   \n",
       "2                 -5.728954            -35123.4340             4982.006300   \n",
       "3                 -2.132175            -29979.5370             5215.574700   \n",
       "4                 34.283890             -5716.5230              437.943730   \n",
       "\n",
       "   autocorelation_00_std  autocorelation_00_sum  chroma_cens_00_kurtosis  \\\n",
       "0               3.016389           7.194268e+03                 1.221379   \n",
       "1               0.790848           1.422519e+03                -0.882889   \n",
       "2               0.158547           4.347565e+04                -0.937324   \n",
       "3               0.071497           6.797144e+05                -0.495610   \n",
       "4               4.025559           4.917499e+07                -0.863015   \n",
       "\n",
       "   chroma_cens_00_max  ...  dtempo_changes  onset_count  low_energy_rate  \\\n",
       "0            0.379768  ...               6          169            184.0   \n",
       "1            0.659657  ...               5          120            364.0   \n",
       "2            0.564553  ...               0          205            278.0   \n",
       "3            0.188383  ...              11          211            191.0   \n",
       "4            0.472208  ...               9          205             88.0   \n",
       "\n",
       "   harmonic_to_noise_rate  dynamic_range  swing_ratio  syncopation  \\\n",
       "0              -14.303785       0.218490     1.109646     0.100849   \n",
       "1                1.258749       0.147046     1.139929     0.312308   \n",
       "2                0.197590       0.661439     1.154552     0.112588   \n",
       "3                0.258297       0.504590     1.079204     0.069990   \n",
       "4                0.470797       0.281950     1.155421     0.107491   \n",
       "\n",
       "     roughness    warmth       Genre  \n",
       "0   191.356035  0.701712  Electronic  \n",
       "1    57.557036  0.605086  Electronic  \n",
       "2  1374.684072  0.611777  Electronic  \n",
       "3  2111.869221  0.401475  Electronic  \n",
       "4   284.493888  0.461459  Electronic  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '..\\\\datasets\\\\fma\\\\fma_small_932_features.csv'\n",
    "df = pd.read_csv(root_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "Electronic       220\n",
       "Experimental      49\n",
       "Folk              39\n",
       "Hip-Hop          117\n",
       "Instrumental      79\n",
       "International     92\n",
       "Pop              110\n",
       "Rock              68\n",
       "Name: dtempo_00_kurtosis, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Genre\"])['dtempo_00_kurtosis'].apply(lambda x:pd.isna(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_genre(df, strategy='mean'):\n",
    "    grouped = df.groupby('Genre')\n",
    "    \n",
    "    if strategy == 'mean':\n",
    "        return grouped.apply(lambda group: group.fillna(group.mean())).reset_index()\n",
    "    elif strategy == 'median':\n",
    "        return grouped.apply(lambda group: group.fillna(group.median())).reset_index()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported strategy. Use 'mean' or 'median'.\")\n",
    "\n",
    "df = impute_by_genre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>autocorelation_00_kurtosis</th>\n",
       "      <th>autocorelation_00_max</th>\n",
       "      <th>autocorelation_00_mean</th>\n",
       "      <th>autocorelation_00_median</th>\n",
       "      <th>autocorelation_00_min</th>\n",
       "      <th>autocorelation_00_skew</th>\n",
       "      <th>autocorelation_00_std</th>\n",
       "      <th>autocorelation_00_sum</th>\n",
       "      <th>chroma_cens_00_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>beat_count</th>\n",
       "      <th>dtempo_changes</th>\n",
       "      <th>onset_count</th>\n",
       "      <th>low_energy_rate</th>\n",
       "      <th>harmonic_to_noise_rate</th>\n",
       "      <th>dynamic_range</th>\n",
       "      <th>swing_ratio</th>\n",
       "      <th>syncopation</th>\n",
       "      <th>roughness</th>\n",
       "      <th>warmth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>141.768500</td>\n",
       "      <td>12364.4260</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>-2.887901</td>\n",
       "      <td>-1593.9122</td>\n",
       "      <td>170.368180</td>\n",
       "      <td>3.016389</td>\n",
       "      <td>7.194268e+03</td>\n",
       "      <td>1.221379</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-14.303785</td>\n",
       "      <td>0.218490</td>\n",
       "      <td>1.109646</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>191.356035</td>\n",
       "      <td>0.701712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>31.686200</td>\n",
       "      <td>2798.3555</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.398690</td>\n",
       "      <td>-1224.2454</td>\n",
       "      <td>88.129974</td>\n",
       "      <td>0.790848</td>\n",
       "      <td>1.422519e+03</td>\n",
       "      <td>-0.882889</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.258749</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>1.139929</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>57.557036</td>\n",
       "      <td>0.605086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>11.787950</td>\n",
       "      <td>65289.0160</td>\n",
       "      <td>0.065771</td>\n",
       "      <td>-5.728954</td>\n",
       "      <td>-35123.4340</td>\n",
       "      <td>4982.006300</td>\n",
       "      <td>0.158547</td>\n",
       "      <td>4.347565e+04</td>\n",
       "      <td>-0.937324</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.661439</td>\n",
       "      <td>1.154552</td>\n",
       "      <td>0.112588</td>\n",
       "      <td>1374.684072</td>\n",
       "      <td>0.611777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>4.609666</td>\n",
       "      <td>60351.8500</td>\n",
       "      <td>1.028323</td>\n",
       "      <td>-2.132175</td>\n",
       "      <td>-29979.5370</td>\n",
       "      <td>5215.574700</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>6.797144e+05</td>\n",
       "      <td>-0.495610</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>211</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.258297</td>\n",
       "      <td>0.504590</td>\n",
       "      <td>1.079204</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>2111.869221</td>\n",
       "      <td>0.401475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>113.699970</td>\n",
       "      <td>22080.5940</td>\n",
       "      <td>74.396010</td>\n",
       "      <td>34.283890</td>\n",
       "      <td>-5716.5230</td>\n",
       "      <td>437.943730</td>\n",
       "      <td>4.025559</td>\n",
       "      <td>4.917499e+07</td>\n",
       "      <td>-0.863015</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.470797</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>1.155421</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>284.493888</td>\n",
       "      <td>0.461459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genre  autocorelation_00_kurtosis  autocorelation_00_max  \\\n",
       "0  Electronic                  141.768500             12364.4260   \n",
       "1  Electronic                   31.686200              2798.3555   \n",
       "2  Electronic                   11.787950             65289.0160   \n",
       "3  Electronic                    4.609666             60351.8500   \n",
       "4  Electronic                  113.699970             22080.5940   \n",
       "\n",
       "   autocorelation_00_mean  autocorelation_00_median  autocorelation_00_min  \\\n",
       "0                0.010876                 -2.887901             -1593.9122   \n",
       "1                0.002150                 -0.398690             -1224.2454   \n",
       "2                0.065771                 -5.728954            -35123.4340   \n",
       "3                1.028323                 -2.132175            -29979.5370   \n",
       "4               74.396010                 34.283890             -5716.5230   \n",
       "\n",
       "   autocorelation_00_skew  autocorelation_00_std  autocorelation_00_sum  \\\n",
       "0              170.368180               3.016389           7.194268e+03   \n",
       "1               88.129974               0.790848           1.422519e+03   \n",
       "2             4982.006300               0.158547           4.347565e+04   \n",
       "3             5215.574700               0.071497           6.797144e+05   \n",
       "4              437.943730               4.025559           4.917499e+07   \n",
       "\n",
       "   chroma_cens_00_kurtosis  ...  beat_count  dtempo_changes  onset_count  \\\n",
       "0                 1.221379  ...          64               6          169   \n",
       "1                -0.882889  ...          41               5          120   \n",
       "2                -0.937324  ...          66               0          205   \n",
       "3                -0.495610  ...          94              11          211   \n",
       "4                -0.863015  ...          72               9          205   \n",
       "\n",
       "   low_energy_rate  harmonic_to_noise_rate  dynamic_range  swing_ratio  \\\n",
       "0            184.0              -14.303785       0.218490     1.109646   \n",
       "1            364.0                1.258749       0.147046     1.139929   \n",
       "2            278.0                0.197590       0.661439     1.154552   \n",
       "3            191.0                0.258297       0.504590     1.079204   \n",
       "4             88.0                0.470797       0.281950     1.155421   \n",
       "\n",
       "   syncopation    roughness    warmth  \n",
       "0     0.100849   191.356035  0.701712  \n",
       "1     0.312308    57.557036  0.605086  \n",
       "2     0.112588  1374.684072  0.611777  \n",
       "3     0.069990  2111.869221  0.401475  \n",
       "4     0.107491   284.493888  0.461459  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"level_1\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5595, 931) (1199, 931) (1199, 931)\n",
      "(5595,) (1199,) (1199,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df['Genre'] = LabelEncoder().fit_transform(df['Genre'])\n",
    "\n",
    "X = df.drop(\"Genre\", axis=1)\n",
    "y = df[\"Genre\"]\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=42)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, stratify=y_test, test_size=0.5, random_state=42)\n",
    "X_test = sc.transform(X_test)\n",
    "X_valid = sc.transform(X_valid)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_valid.shape)\n",
    "print(y_train.shape, y_test.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "n_classes = 8\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, n_classes)\n",
    "y_valid_encoded = to_categorical(y_valid, n_classes)\n",
    "y_test_encoded = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Input(shape=(931,)))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.1)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "175/175 [==============================] - 2s 6ms/step - loss: 3.0315 - accuracy: 0.1376 - val_loss: 2.1476 - val_accuracy: 0.1384\n",
      "Epoch 2/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.6846 - accuracy: 0.1391 - val_loss: 2.1082 - val_accuracy: 0.1301\n",
      "Epoch 3/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.4434 - accuracy: 0.1539 - val_loss: 2.0620 - val_accuracy: 0.1334\n",
      "Epoch 4/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.3118 - accuracy: 0.1584 - val_loss: 2.0245 - val_accuracy: 0.1543\n",
      "Epoch 5/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.2056 - accuracy: 0.1723 - val_loss: 1.9994 - val_accuracy: 0.1751\n",
      "Epoch 6/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.1370 - accuracy: 0.1803 - val_loss: 1.9772 - val_accuracy: 0.2002\n",
      "Epoch 7/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.0869 - accuracy: 0.1911 - val_loss: 1.9570 - val_accuracy: 0.2302\n",
      "Epoch 8/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.0475 - accuracy: 0.1987 - val_loss: 1.9405 - val_accuracy: 0.2435\n",
      "Epoch 9/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.0123 - accuracy: 0.1995 - val_loss: 1.9271 - val_accuracy: 0.2694\n",
      "Epoch 10/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9947 - accuracy: 0.2145 - val_loss: 1.9172 - val_accuracy: 0.2727\n",
      "Epoch 11/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9766 - accuracy: 0.2186 - val_loss: 1.9062 - val_accuracy: 0.2794\n",
      "Epoch 12/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9446 - accuracy: 0.2390 - val_loss: 1.8877 - val_accuracy: 0.2919\n",
      "Epoch 13/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9290 - accuracy: 0.2463 - val_loss: 1.8748 - val_accuracy: 0.2986\n",
      "Epoch 14/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9246 - accuracy: 0.2441 - val_loss: 1.8619 - val_accuracy: 0.3069\n",
      "Epoch 15/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9237 - accuracy: 0.2468 - val_loss: 1.8517 - val_accuracy: 0.3136\n",
      "Epoch 16/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9028 - accuracy: 0.2579 - val_loss: 1.8402 - val_accuracy: 0.3203\n",
      "Epoch 17/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9037 - accuracy: 0.2586 - val_loss: 1.8363 - val_accuracy: 0.3219\n",
      "Epoch 18/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8955 - accuracy: 0.2654 - val_loss: 1.8293 - val_accuracy: 0.3244\n",
      "Epoch 19/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8814 - accuracy: 0.2606 - val_loss: 1.8152 - val_accuracy: 0.3269\n",
      "Epoch 20/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8682 - accuracy: 0.2854 - val_loss: 1.8075 - val_accuracy: 0.3294\n",
      "Epoch 21/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8687 - accuracy: 0.2824 - val_loss: 1.8007 - val_accuracy: 0.3328\n",
      "Epoch 22/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8691 - accuracy: 0.2738 - val_loss: 1.7928 - val_accuracy: 0.3369\n",
      "Epoch 23/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8517 - accuracy: 0.2826 - val_loss: 1.7841 - val_accuracy: 0.3486\n",
      "Epoch 24/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8508 - accuracy: 0.2840 - val_loss: 1.7762 - val_accuracy: 0.3595\n",
      "Epoch 25/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8472 - accuracy: 0.2885 - val_loss: 1.7720 - val_accuracy: 0.3620\n",
      "Epoch 26/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8415 - accuracy: 0.2929 - val_loss: 1.7611 - val_accuracy: 0.3470\n",
      "Epoch 27/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8326 - accuracy: 0.2924 - val_loss: 1.7528 - val_accuracy: 0.3578\n",
      "Epoch 28/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8325 - accuracy: 0.2992 - val_loss: 1.7494 - val_accuracy: 0.3595\n",
      "Epoch 29/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8253 - accuracy: 0.3040 - val_loss: 1.7412 - val_accuracy: 0.3578\n",
      "Epoch 30/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8278 - accuracy: 0.2974 - val_loss: 1.7369 - val_accuracy: 0.3653\n",
      "Epoch 31/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8262 - accuracy: 0.2942 - val_loss: 1.7338 - val_accuracy: 0.3686\n",
      "Epoch 32/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8212 - accuracy: 0.3065 - val_loss: 1.7338 - val_accuracy: 0.3586\n",
      "Epoch 33/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8134 - accuracy: 0.3042 - val_loss: 1.7252 - val_accuracy: 0.3628\n",
      "Epoch 34/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8059 - accuracy: 0.3128 - val_loss: 1.7175 - val_accuracy: 0.3653\n",
      "Epoch 35/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8078 - accuracy: 0.3205 - val_loss: 1.7138 - val_accuracy: 0.3753\n",
      "Epoch 36/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8000 - accuracy: 0.3115 - val_loss: 1.7156 - val_accuracy: 0.3695\n",
      "Epoch 37/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8036 - accuracy: 0.3144 - val_loss: 1.7119 - val_accuracy: 0.3670\n",
      "Epoch 38/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7938 - accuracy: 0.3255 - val_loss: 1.7047 - val_accuracy: 0.3736\n",
      "Epoch 39/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7870 - accuracy: 0.3206 - val_loss: 1.7001 - val_accuracy: 0.3761\n",
      "Epoch 40/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7893 - accuracy: 0.3258 - val_loss: 1.6940 - val_accuracy: 0.3770\n",
      "Epoch 41/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7989 - accuracy: 0.3180 - val_loss: 1.6911 - val_accuracy: 0.3761\n",
      "Epoch 42/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7879 - accuracy: 0.3239 - val_loss: 1.6898 - val_accuracy: 0.3770\n",
      "Epoch 43/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7828 - accuracy: 0.3294 - val_loss: 1.6876 - val_accuracy: 0.3761\n",
      "Epoch 44/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7781 - accuracy: 0.3299 - val_loss: 1.6822 - val_accuracy: 0.3795\n",
      "Epoch 45/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7708 - accuracy: 0.3258 - val_loss: 1.6762 - val_accuracy: 0.3895\n",
      "Epoch 46/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.7630 - accuracy: 0.3217 - val_loss: 1.6717 - val_accuracy: 0.3878\n",
      "Epoch 47/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7558 - accuracy: 0.3303 - val_loss: 1.6685 - val_accuracy: 0.3903\n",
      "Epoch 48/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7762 - accuracy: 0.3203 - val_loss: 1.6669 - val_accuracy: 0.3962\n",
      "Epoch 49/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7695 - accuracy: 0.3315 - val_loss: 1.6645 - val_accuracy: 0.3945\n",
      "Epoch 50/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7503 - accuracy: 0.3383 - val_loss: 1.6603 - val_accuracy: 0.4003\n",
      "Epoch 51/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7469 - accuracy: 0.3374 - val_loss: 1.6543 - val_accuracy: 0.3995\n",
      "Epoch 52/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7495 - accuracy: 0.3501 - val_loss: 1.6556 - val_accuracy: 0.3953\n",
      "Epoch 53/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7337 - accuracy: 0.3462 - val_loss: 1.6485 - val_accuracy: 0.3987\n",
      "Epoch 54/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7528 - accuracy: 0.3439 - val_loss: 1.6448 - val_accuracy: 0.4037\n",
      "Epoch 55/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7403 - accuracy: 0.3505 - val_loss: 1.6401 - val_accuracy: 0.4053\n",
      "Epoch 56/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7421 - accuracy: 0.3428 - val_loss: 1.6385 - val_accuracy: 0.4153\n",
      "Epoch 57/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7262 - accuracy: 0.3528 - val_loss: 1.6374 - val_accuracy: 0.4062\n",
      "Epoch 58/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7378 - accuracy: 0.3580 - val_loss: 1.6343 - val_accuracy: 0.4112\n",
      "Epoch 59/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7432 - accuracy: 0.3435 - val_loss: 1.6293 - val_accuracy: 0.4162\n",
      "Epoch 60/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7326 - accuracy: 0.3491 - val_loss: 1.6266 - val_accuracy: 0.4137\n",
      "Epoch 61/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7282 - accuracy: 0.3500 - val_loss: 1.6227 - val_accuracy: 0.4229\n",
      "Epoch 62/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7148 - accuracy: 0.3655 - val_loss: 1.6151 - val_accuracy: 0.4187\n",
      "Epoch 63/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7157 - accuracy: 0.3539 - val_loss: 1.6107 - val_accuracy: 0.4270\n",
      "Epoch 64/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7283 - accuracy: 0.3562 - val_loss: 1.6083 - val_accuracy: 0.4212\n",
      "Epoch 65/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7072 - accuracy: 0.3535 - val_loss: 1.6041 - val_accuracy: 0.4312\n",
      "Epoch 66/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7165 - accuracy: 0.3555 - val_loss: 1.6023 - val_accuracy: 0.4295\n",
      "Epoch 67/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7127 - accuracy: 0.3575 - val_loss: 1.6002 - val_accuracy: 0.4287\n",
      "Epoch 68/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6916 - accuracy: 0.3696 - val_loss: 1.5910 - val_accuracy: 0.4295\n",
      "Epoch 69/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6966 - accuracy: 0.3744 - val_loss: 1.5896 - val_accuracy: 0.4320\n",
      "Epoch 70/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6996 - accuracy: 0.3628 - val_loss: 1.5902 - val_accuracy: 0.4354\n",
      "Epoch 71/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6947 - accuracy: 0.3587 - val_loss: 1.5832 - val_accuracy: 0.4437\n",
      "Epoch 72/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6837 - accuracy: 0.3746 - val_loss: 1.5781 - val_accuracy: 0.4404\n",
      "Epoch 73/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6877 - accuracy: 0.3634 - val_loss: 1.5792 - val_accuracy: 0.4329\n",
      "Epoch 74/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6729 - accuracy: 0.3757 - val_loss: 1.5750 - val_accuracy: 0.4387\n",
      "Epoch 75/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6826 - accuracy: 0.3739 - val_loss: 1.5691 - val_accuracy: 0.4370\n",
      "Epoch 76/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6824 - accuracy: 0.3728 - val_loss: 1.5635 - val_accuracy: 0.4462\n",
      "Epoch 77/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6767 - accuracy: 0.3757 - val_loss: 1.5664 - val_accuracy: 0.4512\n",
      "Epoch 78/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6653 - accuracy: 0.3857 - val_loss: 1.5619 - val_accuracy: 0.4495\n",
      "Epoch 79/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6691 - accuracy: 0.3803 - val_loss: 1.5559 - val_accuracy: 0.4487\n",
      "Epoch 80/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6647 - accuracy: 0.3834 - val_loss: 1.5507 - val_accuracy: 0.4545\n",
      "Epoch 81/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6649 - accuracy: 0.3875 - val_loss: 1.5476 - val_accuracy: 0.4579\n",
      "Epoch 82/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6665 - accuracy: 0.3825 - val_loss: 1.5473 - val_accuracy: 0.4554\n",
      "Epoch 83/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6596 - accuracy: 0.3936 - val_loss: 1.5439 - val_accuracy: 0.4529\n",
      "Epoch 84/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6584 - accuracy: 0.3886 - val_loss: 1.5390 - val_accuracy: 0.4587\n",
      "Epoch 85/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6321 - accuracy: 0.3977 - val_loss: 1.5404 - val_accuracy: 0.4562\n",
      "Epoch 86/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6555 - accuracy: 0.3903 - val_loss: 1.5376 - val_accuracy: 0.4595\n",
      "Epoch 87/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6414 - accuracy: 0.3937 - val_loss: 1.5357 - val_accuracy: 0.4629\n",
      "Epoch 88/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6584 - accuracy: 0.3868 - val_loss: 1.5299 - val_accuracy: 0.4621\n",
      "Epoch 89/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6392 - accuracy: 0.3957 - val_loss: 1.5265 - val_accuracy: 0.4629\n",
      "Epoch 90/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6188 - accuracy: 0.4013 - val_loss: 1.5263 - val_accuracy: 0.4646\n",
      "Epoch 91/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6297 - accuracy: 0.4102 - val_loss: 1.5233 - val_accuracy: 0.4679\n",
      "Epoch 92/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6285 - accuracy: 0.3934 - val_loss: 1.5141 - val_accuracy: 0.4646\n",
      "Epoch 93/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6177 - accuracy: 0.4100 - val_loss: 1.5168 - val_accuracy: 0.4721\n",
      "Epoch 94/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6080 - accuracy: 0.4043 - val_loss: 1.5097 - val_accuracy: 0.4679\n",
      "Epoch 95/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6281 - accuracy: 0.4002 - val_loss: 1.5113 - val_accuracy: 0.4662\n",
      "Epoch 96/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6224 - accuracy: 0.4041 - val_loss: 1.5081 - val_accuracy: 0.4729\n",
      "Epoch 97/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6158 - accuracy: 0.4102 - val_loss: 1.5044 - val_accuracy: 0.4771\n",
      "Epoch 98/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6102 - accuracy: 0.4073 - val_loss: 1.5045 - val_accuracy: 0.4712\n",
      "Epoch 99/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5983 - accuracy: 0.4079 - val_loss: 1.5020 - val_accuracy: 0.4712\n",
      "Epoch 100/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6155 - accuracy: 0.4029 - val_loss: 1.5013 - val_accuracy: 0.4771\n",
      "Epoch 101/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6024 - accuracy: 0.4097 - val_loss: 1.4961 - val_accuracy: 0.4746\n",
      "Epoch 102/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5987 - accuracy: 0.4166 - val_loss: 1.4957 - val_accuracy: 0.4762\n",
      "Epoch 103/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6057 - accuracy: 0.4198 - val_loss: 1.4939 - val_accuracy: 0.4804\n",
      "Epoch 104/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5986 - accuracy: 0.4113 - val_loss: 1.4890 - val_accuracy: 0.4904\n",
      "Epoch 105/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5840 - accuracy: 0.4220 - val_loss: 1.4850 - val_accuracy: 0.4846\n",
      "Epoch 106/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5804 - accuracy: 0.4186 - val_loss: 1.4780 - val_accuracy: 0.4837\n",
      "Epoch 107/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5902 - accuracy: 0.4200 - val_loss: 1.4744 - val_accuracy: 0.4871\n",
      "Epoch 108/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5894 - accuracy: 0.4243 - val_loss: 1.4754 - val_accuracy: 0.4821\n",
      "Epoch 109/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4232 - val_loss: 1.4776 - val_accuracy: 0.4912\n",
      "Epoch 110/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5877 - accuracy: 0.4229 - val_loss: 1.4727 - val_accuracy: 0.4862\n",
      "Epoch 111/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5654 - accuracy: 0.4252 - val_loss: 1.4691 - val_accuracy: 0.4929\n",
      "Epoch 112/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5636 - accuracy: 0.4261 - val_loss: 1.4693 - val_accuracy: 0.4987\n",
      "Epoch 113/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5727 - accuracy: 0.4320 - val_loss: 1.4599 - val_accuracy: 0.5021\n",
      "Epoch 114/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5610 - accuracy: 0.4354 - val_loss: 1.4602 - val_accuracy: 0.5046\n",
      "Epoch 115/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5503 - accuracy: 0.4388 - val_loss: 1.4575 - val_accuracy: 0.5046\n",
      "Epoch 116/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5610 - accuracy: 0.4363 - val_loss: 1.4553 - val_accuracy: 0.5038\n",
      "Epoch 117/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5497 - accuracy: 0.4388 - val_loss: 1.4571 - val_accuracy: 0.5063\n",
      "Epoch 118/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5603 - accuracy: 0.4356 - val_loss: 1.4523 - val_accuracy: 0.5121\n",
      "Epoch 119/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5656 - accuracy: 0.4275 - val_loss: 1.4476 - val_accuracy: 0.5113\n",
      "Epoch 120/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5579 - accuracy: 0.4284 - val_loss: 1.4436 - val_accuracy: 0.5179\n",
      "Epoch 121/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5530 - accuracy: 0.4413 - val_loss: 1.4411 - val_accuracy: 0.5188\n",
      "Epoch 122/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5492 - accuracy: 0.4359 - val_loss: 1.4417 - val_accuracy: 0.5221\n",
      "Epoch 123/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5342 - accuracy: 0.4456 - val_loss: 1.4364 - val_accuracy: 0.5204\n",
      "Epoch 124/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5338 - accuracy: 0.4420 - val_loss: 1.4365 - val_accuracy: 0.5188\n",
      "Epoch 125/800\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.5240 - accuracy: 0.4504 - val_loss: 1.4329 - val_accuracy: 0.5154\n",
      "Epoch 126/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5132 - accuracy: 0.4484 - val_loss: 1.4284 - val_accuracy: 0.5196\n",
      "Epoch 127/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5194 - accuracy: 0.4538 - val_loss: 1.4281 - val_accuracy: 0.5163\n",
      "Epoch 128/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5320 - accuracy: 0.4515 - val_loss: 1.4241 - val_accuracy: 0.5171\n",
      "Epoch 129/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5317 - accuracy: 0.4490 - val_loss: 1.4223 - val_accuracy: 0.5204\n",
      "Epoch 130/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5120 - accuracy: 0.4497 - val_loss: 1.4250 - val_accuracy: 0.5154\n",
      "Epoch 131/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5113 - accuracy: 0.4583 - val_loss: 1.4223 - val_accuracy: 0.5171\n",
      "Epoch 132/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5186 - accuracy: 0.4533 - val_loss: 1.4202 - val_accuracy: 0.5221\n",
      "Epoch 133/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5085 - accuracy: 0.4549 - val_loss: 1.4203 - val_accuracy: 0.5246\n",
      "Epoch 134/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4970 - accuracy: 0.4590 - val_loss: 1.4165 - val_accuracy: 0.5238\n",
      "Epoch 135/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5101 - accuracy: 0.4609 - val_loss: 1.4094 - val_accuracy: 0.5254\n",
      "Epoch 136/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5100 - accuracy: 0.4577 - val_loss: 1.4093 - val_accuracy: 0.5313\n",
      "Epoch 137/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5025 - accuracy: 0.4660 - val_loss: 1.4052 - val_accuracy: 0.5246\n",
      "Epoch 138/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4776 - accuracy: 0.4785 - val_loss: 1.4053 - val_accuracy: 0.5279\n",
      "Epoch 139/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4963 - accuracy: 0.4683 - val_loss: 1.4050 - val_accuracy: 0.5329\n",
      "Epoch 140/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5008 - accuracy: 0.4760 - val_loss: 1.4058 - val_accuracy: 0.5229\n",
      "Epoch 141/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4825 - accuracy: 0.4663 - val_loss: 1.4022 - val_accuracy: 0.5279\n",
      "Epoch 142/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4854 - accuracy: 0.4713 - val_loss: 1.4018 - val_accuracy: 0.5271\n",
      "Epoch 143/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4694 - accuracy: 0.4769 - val_loss: 1.3989 - val_accuracy: 0.5279\n",
      "Epoch 144/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4805 - accuracy: 0.4720 - val_loss: 1.3967 - val_accuracy: 0.5263\n",
      "Epoch 145/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4612 - accuracy: 0.4735 - val_loss: 1.3918 - val_accuracy: 0.5321\n",
      "Epoch 146/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4691 - accuracy: 0.4726 - val_loss: 1.3927 - val_accuracy: 0.5313\n",
      "Epoch 147/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4462 - accuracy: 0.4867 - val_loss: 1.3918 - val_accuracy: 0.5279\n",
      "Epoch 148/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4679 - accuracy: 0.4744 - val_loss: 1.3862 - val_accuracy: 0.5363\n",
      "Epoch 149/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4673 - accuracy: 0.4797 - val_loss: 1.3896 - val_accuracy: 0.5338\n",
      "Epoch 150/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4569 - accuracy: 0.4744 - val_loss: 1.3883 - val_accuracy: 0.5363\n",
      "Epoch 151/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4425 - accuracy: 0.4854 - val_loss: 1.3832 - val_accuracy: 0.5338\n",
      "Epoch 152/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4710 - accuracy: 0.4747 - val_loss: 1.3804 - val_accuracy: 0.5405\n",
      "Epoch 153/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4587 - accuracy: 0.4795 - val_loss: 1.3826 - val_accuracy: 0.5363\n",
      "Epoch 154/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4370 - accuracy: 0.4947 - val_loss: 1.3774 - val_accuracy: 0.5388\n",
      "Epoch 155/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4423 - accuracy: 0.4819 - val_loss: 1.3778 - val_accuracy: 0.5396\n",
      "Epoch 156/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4444 - accuracy: 0.4845 - val_loss: 1.3759 - val_accuracy: 0.5396\n",
      "Epoch 157/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4513 - accuracy: 0.4922 - val_loss: 1.3791 - val_accuracy: 0.5338\n",
      "Epoch 158/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4347 - accuracy: 0.4919 - val_loss: 1.3770 - val_accuracy: 0.5288\n",
      "Epoch 159/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4331 - accuracy: 0.4947 - val_loss: 1.3774 - val_accuracy: 0.5354\n",
      "Epoch 160/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4469 - accuracy: 0.4892 - val_loss: 1.3715 - val_accuracy: 0.5388\n",
      "Epoch 161/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4449 - accuracy: 0.4788 - val_loss: 1.3690 - val_accuracy: 0.5438\n",
      "Epoch 162/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4127 - accuracy: 0.4915 - val_loss: 1.3690 - val_accuracy: 0.5388\n",
      "Epoch 163/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4297 - accuracy: 0.4887 - val_loss: 1.3678 - val_accuracy: 0.5371\n",
      "Epoch 164/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4261 - accuracy: 0.5003 - val_loss: 1.3612 - val_accuracy: 0.5379\n",
      "Epoch 165/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4101 - accuracy: 0.4922 - val_loss: 1.3611 - val_accuracy: 0.5421\n",
      "Epoch 166/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4092 - accuracy: 0.4988 - val_loss: 1.3604 - val_accuracy: 0.5480\n",
      "Epoch 167/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4124 - accuracy: 0.4944 - val_loss: 1.3540 - val_accuracy: 0.5463\n",
      "Epoch 168/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4163 - accuracy: 0.4958 - val_loss: 1.3610 - val_accuracy: 0.5405\n",
      "Epoch 169/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4108 - accuracy: 0.5013 - val_loss: 1.3581 - val_accuracy: 0.5463\n",
      "Epoch 170/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4164 - accuracy: 0.4953 - val_loss: 1.3563 - val_accuracy: 0.5463\n",
      "Epoch 171/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4265 - accuracy: 0.4895 - val_loss: 1.3546 - val_accuracy: 0.5471\n",
      "Epoch 172/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3960 - accuracy: 0.5071 - val_loss: 1.3458 - val_accuracy: 0.5480\n",
      "Epoch 173/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4005 - accuracy: 0.5110 - val_loss: 1.3490 - val_accuracy: 0.5446\n",
      "Epoch 174/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3784 - accuracy: 0.5205 - val_loss: 1.3481 - val_accuracy: 0.5471\n",
      "Epoch 175/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3752 - accuracy: 0.5149 - val_loss: 1.3468 - val_accuracy: 0.5496\n",
      "Epoch 176/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4126 - accuracy: 0.4974 - val_loss: 1.3435 - val_accuracy: 0.5463\n",
      "Epoch 177/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3926 - accuracy: 0.5124 - val_loss: 1.3400 - val_accuracy: 0.5505\n",
      "Epoch 178/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3710 - accuracy: 0.5119 - val_loss: 1.3483 - val_accuracy: 0.5430\n",
      "Epoch 179/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3929 - accuracy: 0.5162 - val_loss: 1.3428 - val_accuracy: 0.5488\n",
      "Epoch 180/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3779 - accuracy: 0.5047 - val_loss: 1.3435 - val_accuracy: 0.5463\n",
      "Epoch 181/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3590 - accuracy: 0.5164 - val_loss: 1.3361 - val_accuracy: 0.5471\n",
      "Epoch 182/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3797 - accuracy: 0.5151 - val_loss: 1.3341 - val_accuracy: 0.5430\n",
      "Epoch 183/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3776 - accuracy: 0.5117 - val_loss: 1.3371 - val_accuracy: 0.5488\n",
      "Epoch 184/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3504 - accuracy: 0.5228 - val_loss: 1.3392 - val_accuracy: 0.5546\n",
      "Epoch 185/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3658 - accuracy: 0.5255 - val_loss: 1.3365 - val_accuracy: 0.5538\n",
      "Epoch 186/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3714 - accuracy: 0.5203 - val_loss: 1.3299 - val_accuracy: 0.5555\n",
      "Epoch 187/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3575 - accuracy: 0.5265 - val_loss: 1.3331 - val_accuracy: 0.5538\n",
      "Epoch 188/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3699 - accuracy: 0.5274 - val_loss: 1.3328 - val_accuracy: 0.5538\n",
      "Epoch 189/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3690 - accuracy: 0.5144 - val_loss: 1.3312 - val_accuracy: 0.5530\n",
      "Epoch 190/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3567 - accuracy: 0.5226 - val_loss: 1.3320 - val_accuracy: 0.5588\n",
      "Epoch 191/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3370 - accuracy: 0.5323 - val_loss: 1.3238 - val_accuracy: 0.5613\n",
      "Epoch 192/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3617 - accuracy: 0.5278 - val_loss: 1.3281 - val_accuracy: 0.5596\n",
      "Epoch 193/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3277 - accuracy: 0.5239 - val_loss: 1.3192 - val_accuracy: 0.5580\n",
      "Epoch 194/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3240 - accuracy: 0.5355 - val_loss: 1.3259 - val_accuracy: 0.5571\n",
      "Epoch 195/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3465 - accuracy: 0.5265 - val_loss: 1.3259 - val_accuracy: 0.5613\n",
      "Epoch 196/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3662 - accuracy: 0.5214 - val_loss: 1.3261 - val_accuracy: 0.5605\n",
      "Epoch 197/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3600 - accuracy: 0.5256 - val_loss: 1.3217 - val_accuracy: 0.5630\n",
      "Epoch 198/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3224 - accuracy: 0.5357 - val_loss: 1.3239 - val_accuracy: 0.5571\n",
      "Epoch 199/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3287 - accuracy: 0.5346 - val_loss: 1.3196 - val_accuracy: 0.5630\n",
      "Epoch 200/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3474 - accuracy: 0.5287 - val_loss: 1.3203 - val_accuracy: 0.5613\n",
      "Epoch 201/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3347 - accuracy: 0.5360 - val_loss: 1.3208 - val_accuracy: 0.5521\n",
      "Epoch 202/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3204 - accuracy: 0.5391 - val_loss: 1.3202 - val_accuracy: 0.5530\n",
      "Epoch 203/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3228 - accuracy: 0.5378 - val_loss: 1.3194 - val_accuracy: 0.5588\n",
      "Epoch 204/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3214 - accuracy: 0.5405 - val_loss: 1.3225 - val_accuracy: 0.5546\n",
      "Epoch 205/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3324 - accuracy: 0.5333 - val_loss: 1.3154 - val_accuracy: 0.5530\n",
      "Epoch 206/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3044 - accuracy: 0.5401 - val_loss: 1.3075 - val_accuracy: 0.5621\n",
      "Epoch 207/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3072 - accuracy: 0.5430 - val_loss: 1.3033 - val_accuracy: 0.5613\n",
      "Epoch 208/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3041 - accuracy: 0.5508 - val_loss: 1.3039 - val_accuracy: 0.5655\n",
      "Epoch 209/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2990 - accuracy: 0.5451 - val_loss: 1.3082 - val_accuracy: 0.5596\n",
      "Epoch 210/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2878 - accuracy: 0.5492 - val_loss: 1.3034 - val_accuracy: 0.5705\n",
      "Epoch 211/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3104 - accuracy: 0.5439 - val_loss: 1.3084 - val_accuracy: 0.5705\n",
      "Epoch 212/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2891 - accuracy: 0.5476 - val_loss: 1.3152 - val_accuracy: 0.5630\n",
      "Epoch 213/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3101 - accuracy: 0.5553 - val_loss: 1.3129 - val_accuracy: 0.5646\n",
      "Epoch 214/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3170 - accuracy: 0.5458 - val_loss: 1.3063 - val_accuracy: 0.5638\n",
      "Epoch 215/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2749 - accuracy: 0.5571 - val_loss: 1.3060 - val_accuracy: 0.5596\n",
      "Epoch 216/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3095 - accuracy: 0.5448 - val_loss: 1.3125 - val_accuracy: 0.5621\n",
      "Epoch 217/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3001 - accuracy: 0.5466 - val_loss: 1.3007 - val_accuracy: 0.5755\n",
      "Epoch 218/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2826 - accuracy: 0.5535 - val_loss: 1.3073 - val_accuracy: 0.5713\n",
      "Epoch 219/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2762 - accuracy: 0.5532 - val_loss: 1.3083 - val_accuracy: 0.5630\n",
      "Epoch 220/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2815 - accuracy: 0.5576 - val_loss: 1.3069 - val_accuracy: 0.5696\n",
      "Epoch 221/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2827 - accuracy: 0.5610 - val_loss: 1.3135 - val_accuracy: 0.5621\n",
      "Epoch 222/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2798 - accuracy: 0.5607 - val_loss: 1.3010 - val_accuracy: 0.5721\n",
      "Epoch 223/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2954 - accuracy: 0.5446 - val_loss: 1.3065 - val_accuracy: 0.5680\n",
      "Epoch 224/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2743 - accuracy: 0.5584 - val_loss: 1.3179 - val_accuracy: 0.5630\n",
      "Epoch 225/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2756 - accuracy: 0.5553 - val_loss: 1.3040 - val_accuracy: 0.5771\n",
      "Epoch 226/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2491 - accuracy: 0.5669 - val_loss: 1.3075 - val_accuracy: 0.5671\n",
      "Epoch 227/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2577 - accuracy: 0.5660 - val_loss: 1.3076 - val_accuracy: 0.5663\n",
      "Epoch 228/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2516 - accuracy: 0.5669 - val_loss: 1.3082 - val_accuracy: 0.5746\n",
      "Epoch 229/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2684 - accuracy: 0.5630 - val_loss: 1.3086 - val_accuracy: 0.5696\n",
      "Epoch 230/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2585 - accuracy: 0.5614 - val_loss: 1.3038 - val_accuracy: 0.5730\n",
      "Epoch 231/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2641 - accuracy: 0.5601 - val_loss: 1.3119 - val_accuracy: 0.5680\n",
      "Epoch 232/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2547 - accuracy: 0.5737 - val_loss: 1.3048 - val_accuracy: 0.5655\n",
      "Epoch 233/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2548 - accuracy: 0.5603 - val_loss: 1.3016 - val_accuracy: 0.5763\n",
      "Epoch 234/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2375 - accuracy: 0.5639 - val_loss: 1.3063 - val_accuracy: 0.5755\n",
      "Epoch 235/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2394 - accuracy: 0.5762 - val_loss: 1.3068 - val_accuracy: 0.5713\n",
      "Epoch 236/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2434 - accuracy: 0.5698 - val_loss: 1.3083 - val_accuracy: 0.5680\n",
      "Epoch 237/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2284 - accuracy: 0.5702 - val_loss: 1.3087 - val_accuracy: 0.5646\n",
      "Epoch 238/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2287 - accuracy: 0.5710 - val_loss: 1.3060 - val_accuracy: 0.5696\n",
      "Epoch 239/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2500 - accuracy: 0.5719 - val_loss: 1.2986 - val_accuracy: 0.5730\n",
      "Epoch 240/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2292 - accuracy: 0.5660 - val_loss: 1.2949 - val_accuracy: 0.5721\n",
      "Epoch 241/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2317 - accuracy: 0.5725 - val_loss: 1.2952 - val_accuracy: 0.5763\n",
      "Epoch 242/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2315 - accuracy: 0.5662 - val_loss: 1.2957 - val_accuracy: 0.5771\n",
      "Epoch 243/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2281 - accuracy: 0.5698 - val_loss: 1.2908 - val_accuracy: 0.5780\n",
      "Epoch 244/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1957 - accuracy: 0.5827 - val_loss: 1.2966 - val_accuracy: 0.5755\n",
      "Epoch 245/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2340 - accuracy: 0.5757 - val_loss: 1.2958 - val_accuracy: 0.5738\n",
      "Epoch 246/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2210 - accuracy: 0.5743 - val_loss: 1.2931 - val_accuracy: 0.5771\n",
      "Epoch 247/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2114 - accuracy: 0.5843 - val_loss: 1.2884 - val_accuracy: 0.5780\n",
      "Epoch 248/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2142 - accuracy: 0.5775 - val_loss: 1.2889 - val_accuracy: 0.5822\n",
      "Epoch 249/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1949 - accuracy: 0.5962 - val_loss: 1.2899 - val_accuracy: 0.5688\n",
      "Epoch 250/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2215 - accuracy: 0.5777 - val_loss: 1.2936 - val_accuracy: 0.5738\n",
      "Epoch 251/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2064 - accuracy: 0.5830 - val_loss: 1.2930 - val_accuracy: 0.5713\n",
      "Epoch 252/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2139 - accuracy: 0.5970 - val_loss: 1.2979 - val_accuracy: 0.5713\n",
      "Epoch 253/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1888 - accuracy: 0.5868 - val_loss: 1.2911 - val_accuracy: 0.5746\n",
      "Epoch 254/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1932 - accuracy: 0.5898 - val_loss: 1.2948 - val_accuracy: 0.5730\n",
      "Epoch 255/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1943 - accuracy: 0.5866 - val_loss: 1.2884 - val_accuracy: 0.5755\n",
      "Epoch 256/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1861 - accuracy: 0.5991 - val_loss: 1.2905 - val_accuracy: 0.5813\n",
      "Epoch 257/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2079 - accuracy: 0.5855 - val_loss: 1.2984 - val_accuracy: 0.5730\n",
      "Epoch 258/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1947 - accuracy: 0.5911 - val_loss: 1.2943 - val_accuracy: 0.5805\n",
      "Epoch 259/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1804 - accuracy: 0.5984 - val_loss: 1.2883 - val_accuracy: 0.5813\n",
      "Epoch 260/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1978 - accuracy: 0.5798 - val_loss: 1.2974 - val_accuracy: 0.5838\n",
      "Epoch 261/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1768 - accuracy: 0.5859 - val_loss: 1.2993 - val_accuracy: 0.5796\n",
      "Epoch 262/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2019 - accuracy: 0.5861 - val_loss: 1.2925 - val_accuracy: 0.5805\n",
      "Epoch 263/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1736 - accuracy: 0.5929 - val_loss: 1.2797 - val_accuracy: 0.5872\n",
      "Epoch 264/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1961 - accuracy: 0.5882 - val_loss: 1.2950 - val_accuracy: 0.5822\n",
      "Epoch 265/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1829 - accuracy: 0.5980 - val_loss: 1.2953 - val_accuracy: 0.5796\n",
      "Epoch 266/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1628 - accuracy: 0.6048 - val_loss: 1.2936 - val_accuracy: 0.5763\n",
      "Epoch 267/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1712 - accuracy: 0.5993 - val_loss: 1.2935 - val_accuracy: 0.5763\n",
      "Epoch 268/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1760 - accuracy: 0.5923 - val_loss: 1.2978 - val_accuracy: 0.5813\n",
      "Epoch 269/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1806 - accuracy: 0.6005 - val_loss: 1.2960 - val_accuracy: 0.5822\n",
      "Epoch 270/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1607 - accuracy: 0.6093 - val_loss: 1.3030 - val_accuracy: 0.5830\n",
      "Epoch 271/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1458 - accuracy: 0.6086 - val_loss: 1.2997 - val_accuracy: 0.5805\n",
      "Epoch 272/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1570 - accuracy: 0.6046 - val_loss: 1.2976 - val_accuracy: 0.5847\n",
      "Epoch 273/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1545 - accuracy: 0.6077 - val_loss: 1.2925 - val_accuracy: 0.5897\n",
      "Epoch 274/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1481 - accuracy: 0.6029 - val_loss: 1.2943 - val_accuracy: 0.5813\n",
      "Epoch 275/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1504 - accuracy: 0.6132 - val_loss: 1.3021 - val_accuracy: 0.5847\n",
      "Epoch 276/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1494 - accuracy: 0.6109 - val_loss: 1.3000 - val_accuracy: 0.5847\n",
      "Epoch 277/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1211 - accuracy: 0.6200 - val_loss: 1.3044 - val_accuracy: 0.5796\n",
      "Epoch 278/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1461 - accuracy: 0.6104 - val_loss: 1.3018 - val_accuracy: 0.5813\n",
      "Epoch 279/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1310 - accuracy: 0.6097 - val_loss: 1.3051 - val_accuracy: 0.5788\n",
      "Epoch 280/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1441 - accuracy: 0.6143 - val_loss: 1.3019 - val_accuracy: 0.5805\n",
      "Epoch 281/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1186 - accuracy: 0.6130 - val_loss: 1.3020 - val_accuracy: 0.5788\n",
      "Epoch 282/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1259 - accuracy: 0.6141 - val_loss: 1.3040 - val_accuracy: 0.5805\n",
      "Epoch 283/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1278 - accuracy: 0.6163 - val_loss: 1.3011 - val_accuracy: 0.5813\n",
      "Epoch 284/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1440 - accuracy: 0.6170 - val_loss: 1.3112 - val_accuracy: 0.5655\n",
      "Epoch 285/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1250 - accuracy: 0.6091 - val_loss: 1.3038 - val_accuracy: 0.5813\n",
      "Epoch 286/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1392 - accuracy: 0.6143 - val_loss: 1.3052 - val_accuracy: 0.5755\n",
      "Epoch 287/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1301 - accuracy: 0.6143 - val_loss: 1.3141 - val_accuracy: 0.5738\n",
      "Epoch 288/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1376 - accuracy: 0.6197 - val_loss: 1.3082 - val_accuracy: 0.5796\n",
      "Epoch 289/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1416 - accuracy: 0.6025 - val_loss: 1.2975 - val_accuracy: 0.5805\n",
      "Epoch 290/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1203 - accuracy: 0.6104 - val_loss: 1.3045 - val_accuracy: 0.5855\n",
      "Epoch 291/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1346 - accuracy: 0.6118 - val_loss: 1.3007 - val_accuracy: 0.5780\n",
      "Epoch 292/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1319 - accuracy: 0.6136 - val_loss: 1.3164 - val_accuracy: 0.5738\n",
      "Epoch 293/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1218 - accuracy: 0.6232 - val_loss: 1.3163 - val_accuracy: 0.5788\n",
      "Epoch 294/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1161 - accuracy: 0.6202 - val_loss: 1.3089 - val_accuracy: 0.5780\n",
      "Epoch 295/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1296 - accuracy: 0.6105 - val_loss: 1.2993 - val_accuracy: 0.5805\n",
      "Epoch 296/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1141 - accuracy: 0.6248 - val_loss: 1.3076 - val_accuracy: 0.5805\n",
      "Epoch 297/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1425 - accuracy: 0.6122 - val_loss: 1.3085 - val_accuracy: 0.5805\n",
      "Epoch 298/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0938 - accuracy: 0.6349 - val_loss: 1.3012 - val_accuracy: 0.5855\n",
      "Epoch 299/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1080 - accuracy: 0.6273 - val_loss: 1.3029 - val_accuracy: 0.5872\n",
      "Epoch 300/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.6356 - val_loss: 1.2998 - val_accuracy: 0.5880\n",
      "Epoch 301/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1017 - accuracy: 0.6277 - val_loss: 1.3107 - val_accuracy: 0.5788\n",
      "Epoch 302/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.0881 - accuracy: 0.6293 - val_loss: 1.2940 - val_accuracy: 0.5913\n",
      "Epoch 303/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1026 - accuracy: 0.6284 - val_loss: 1.3002 - val_accuracy: 0.5905\n",
      "Epoch 304/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0732 - accuracy: 0.6343 - val_loss: 1.3150 - val_accuracy: 0.5796\n",
      "Epoch 305/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1003 - accuracy: 0.6261 - val_loss: 1.3153 - val_accuracy: 0.5863\n",
      "Epoch 306/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0727 - accuracy: 0.6377 - val_loss: 1.3199 - val_accuracy: 0.5780\n",
      "Epoch 307/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0963 - accuracy: 0.6356 - val_loss: 1.3139 - val_accuracy: 0.5830\n",
      "Epoch 308/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0850 - accuracy: 0.6281 - val_loss: 1.2974 - val_accuracy: 0.5947\n",
      "Epoch 309/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0855 - accuracy: 0.6250 - val_loss: 1.3106 - val_accuracy: 0.5913\n",
      "Epoch 310/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0838 - accuracy: 0.6336 - val_loss: 1.3107 - val_accuracy: 0.5872\n",
      "Epoch 311/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0887 - accuracy: 0.6257 - val_loss: 1.3139 - val_accuracy: 0.5771\n",
      "Epoch 312/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.0711 - accuracy: 0.6456 - val_loss: 1.3101 - val_accuracy: 0.5863\n",
      "Epoch 313/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1024 - accuracy: 0.6309 - val_loss: 1.3090 - val_accuracy: 0.5847\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "logs = Path() / \"my_logs\" / \"run_\" / \"Self\"\n",
    "checkpoint_filepath = \"my_checkpoints.Self.model.keras\"\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=logs)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=800, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 1.2783 - accuracy: 0.5721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2782644033432007, 0.5721434354782104]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
