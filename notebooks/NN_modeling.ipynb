{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autocorelation_00_kurtosis</th>\n",
       "      <th>autocorelation_00_max</th>\n",
       "      <th>autocorelation_00_mean</th>\n",
       "      <th>autocorelation_00_median</th>\n",
       "      <th>autocorelation_00_min</th>\n",
       "      <th>autocorelation_00_skew</th>\n",
       "      <th>autocorelation_00_std</th>\n",
       "      <th>autocorelation_00_sum</th>\n",
       "      <th>chroma_cens_00_kurtosis</th>\n",
       "      <th>chroma_cens_00_max</th>\n",
       "      <th>...</th>\n",
       "      <th>dtempo_changes</th>\n",
       "      <th>onset_count</th>\n",
       "      <th>low_energy_rate</th>\n",
       "      <th>harmonic_to_noise_rate</th>\n",
       "      <th>dynamic_range</th>\n",
       "      <th>swing_ratio</th>\n",
       "      <th>syncopation</th>\n",
       "      <th>roughness</th>\n",
       "      <th>warmth</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.768500</td>\n",
       "      <td>12364.4260</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>-2.887901</td>\n",
       "      <td>-1593.9122</td>\n",
       "      <td>170.368180</td>\n",
       "      <td>3.016389</td>\n",
       "      <td>7.194268e+03</td>\n",
       "      <td>1.221379</td>\n",
       "      <td>0.379768</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-14.303785</td>\n",
       "      <td>0.218490</td>\n",
       "      <td>1.109646</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>191.356035</td>\n",
       "      <td>0.701712</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.686200</td>\n",
       "      <td>2798.3555</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.398690</td>\n",
       "      <td>-1224.2454</td>\n",
       "      <td>88.129974</td>\n",
       "      <td>0.790848</td>\n",
       "      <td>1.422519e+03</td>\n",
       "      <td>-0.882889</td>\n",
       "      <td>0.659657</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.258749</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>1.139929</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>57.557036</td>\n",
       "      <td>0.605086</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.787950</td>\n",
       "      <td>65289.0160</td>\n",
       "      <td>0.065771</td>\n",
       "      <td>-5.728954</td>\n",
       "      <td>-35123.4340</td>\n",
       "      <td>4982.006300</td>\n",
       "      <td>0.158547</td>\n",
       "      <td>4.347565e+04</td>\n",
       "      <td>-0.937324</td>\n",
       "      <td>0.564553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.661439</td>\n",
       "      <td>1.154552</td>\n",
       "      <td>0.112588</td>\n",
       "      <td>1374.684072</td>\n",
       "      <td>0.611777</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.609666</td>\n",
       "      <td>60351.8500</td>\n",
       "      <td>1.028323</td>\n",
       "      <td>-2.132175</td>\n",
       "      <td>-29979.5370</td>\n",
       "      <td>5215.574700</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>6.797144e+05</td>\n",
       "      <td>-0.495610</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>211</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.258297</td>\n",
       "      <td>0.504590</td>\n",
       "      <td>1.079204</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>2111.869221</td>\n",
       "      <td>0.401475</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.699970</td>\n",
       "      <td>22080.5940</td>\n",
       "      <td>74.396010</td>\n",
       "      <td>34.283890</td>\n",
       "      <td>-5716.5230</td>\n",
       "      <td>437.943730</td>\n",
       "      <td>4.025559</td>\n",
       "      <td>4.917499e+07</td>\n",
       "      <td>-0.863015</td>\n",
       "      <td>0.472208</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.470797</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>1.155421</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>284.493888</td>\n",
       "      <td>0.461459</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   autocorelation_00_kurtosis  autocorelation_00_max  autocorelation_00_mean  \\\n",
       "0                  141.768500             12364.4260                0.010876   \n",
       "1                   31.686200              2798.3555                0.002150   \n",
       "2                   11.787950             65289.0160                0.065771   \n",
       "3                    4.609666             60351.8500                1.028323   \n",
       "4                  113.699970             22080.5940               74.396010   \n",
       "\n",
       "   autocorelation_00_median  autocorelation_00_min  autocorelation_00_skew  \\\n",
       "0                 -2.887901             -1593.9122              170.368180   \n",
       "1                 -0.398690             -1224.2454               88.129974   \n",
       "2                 -5.728954            -35123.4340             4982.006300   \n",
       "3                 -2.132175            -29979.5370             5215.574700   \n",
       "4                 34.283890             -5716.5230              437.943730   \n",
       "\n",
       "   autocorelation_00_std  autocorelation_00_sum  chroma_cens_00_kurtosis  \\\n",
       "0               3.016389           7.194268e+03                 1.221379   \n",
       "1               0.790848           1.422519e+03                -0.882889   \n",
       "2               0.158547           4.347565e+04                -0.937324   \n",
       "3               0.071497           6.797144e+05                -0.495610   \n",
       "4               4.025559           4.917499e+07                -0.863015   \n",
       "\n",
       "   chroma_cens_00_max  ...  dtempo_changes  onset_count  low_energy_rate  \\\n",
       "0            0.379768  ...               6          169            184.0   \n",
       "1            0.659657  ...               5          120            364.0   \n",
       "2            0.564553  ...               0          205            278.0   \n",
       "3            0.188383  ...              11          211            191.0   \n",
       "4            0.472208  ...               9          205             88.0   \n",
       "\n",
       "   harmonic_to_noise_rate  dynamic_range  swing_ratio  syncopation  \\\n",
       "0              -14.303785       0.218490     1.109646     0.100849   \n",
       "1                1.258749       0.147046     1.139929     0.312308   \n",
       "2                0.197590       0.661439     1.154552     0.112588   \n",
       "3                0.258297       0.504590     1.079204     0.069990   \n",
       "4                0.470797       0.281950     1.155421     0.107491   \n",
       "\n",
       "     roughness    warmth       Genre  \n",
       "0   191.356035  0.701712  Electronic  \n",
       "1    57.557036  0.605086  Electronic  \n",
       "2  1374.684072  0.611777  Electronic  \n",
       "3  2111.869221  0.401475  Electronic  \n",
       "4   284.493888  0.461459  Electronic  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '..\\\\datasets\\\\fma\\\\fma_small_932_features.csv'\n",
    "df = pd.read_csv(root_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "Electronic       220\n",
       "Experimental      49\n",
       "Folk              39\n",
       "Hip-Hop          117\n",
       "Instrumental      79\n",
       "International     92\n",
       "Pop              110\n",
       "Rock              68\n",
       "Name: dtempo_00_kurtosis, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Genre\"])['dtempo_00_kurtosis'].apply(lambda x:pd.isna(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_genre(df, strategy='mean'):\n",
    "    grouped = df.groupby('Genre')\n",
    "    \n",
    "    if strategy == 'mean':\n",
    "        return grouped.apply(lambda group: group.fillna(group.mean())).reset_index()\n",
    "    elif strategy == 'median':\n",
    "        return grouped.apply(lambda group: group.fillna(group.median())).reset_index()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported strategy. Use 'mean' or 'median'.\")\n",
    "\n",
    "df = impute_by_genre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>autocorelation_00_kurtosis</th>\n",
       "      <th>autocorelation_00_max</th>\n",
       "      <th>autocorelation_00_mean</th>\n",
       "      <th>autocorelation_00_median</th>\n",
       "      <th>autocorelation_00_min</th>\n",
       "      <th>autocorelation_00_skew</th>\n",
       "      <th>autocorelation_00_std</th>\n",
       "      <th>autocorelation_00_sum</th>\n",
       "      <th>chroma_cens_00_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>beat_count</th>\n",
       "      <th>dtempo_changes</th>\n",
       "      <th>onset_count</th>\n",
       "      <th>low_energy_rate</th>\n",
       "      <th>harmonic_to_noise_rate</th>\n",
       "      <th>dynamic_range</th>\n",
       "      <th>swing_ratio</th>\n",
       "      <th>syncopation</th>\n",
       "      <th>roughness</th>\n",
       "      <th>warmth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>141.768500</td>\n",
       "      <td>12364.4260</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>-2.887901</td>\n",
       "      <td>-1593.9122</td>\n",
       "      <td>170.368180</td>\n",
       "      <td>3.016389</td>\n",
       "      <td>7.194268e+03</td>\n",
       "      <td>1.221379</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-14.303785</td>\n",
       "      <td>0.218490</td>\n",
       "      <td>1.109646</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>191.356035</td>\n",
       "      <td>0.701712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>31.686200</td>\n",
       "      <td>2798.3555</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.398690</td>\n",
       "      <td>-1224.2454</td>\n",
       "      <td>88.129974</td>\n",
       "      <td>0.790848</td>\n",
       "      <td>1.422519e+03</td>\n",
       "      <td>-0.882889</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.258749</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>1.139929</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>57.557036</td>\n",
       "      <td>0.605086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>11.787950</td>\n",
       "      <td>65289.0160</td>\n",
       "      <td>0.065771</td>\n",
       "      <td>-5.728954</td>\n",
       "      <td>-35123.4340</td>\n",
       "      <td>4982.006300</td>\n",
       "      <td>0.158547</td>\n",
       "      <td>4.347565e+04</td>\n",
       "      <td>-0.937324</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.661439</td>\n",
       "      <td>1.154552</td>\n",
       "      <td>0.112588</td>\n",
       "      <td>1374.684072</td>\n",
       "      <td>0.611777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>4.609666</td>\n",
       "      <td>60351.8500</td>\n",
       "      <td>1.028323</td>\n",
       "      <td>-2.132175</td>\n",
       "      <td>-29979.5370</td>\n",
       "      <td>5215.574700</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>6.797144e+05</td>\n",
       "      <td>-0.495610</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>211</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.258297</td>\n",
       "      <td>0.504590</td>\n",
       "      <td>1.079204</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>2111.869221</td>\n",
       "      <td>0.401475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>113.699970</td>\n",
       "      <td>22080.5940</td>\n",
       "      <td>74.396010</td>\n",
       "      <td>34.283890</td>\n",
       "      <td>-5716.5230</td>\n",
       "      <td>437.943730</td>\n",
       "      <td>4.025559</td>\n",
       "      <td>4.917499e+07</td>\n",
       "      <td>-0.863015</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.470797</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>1.155421</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>284.493888</td>\n",
       "      <td>0.461459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genre  autocorelation_00_kurtosis  autocorelation_00_max  \\\n",
       "0  Electronic                  141.768500             12364.4260   \n",
       "1  Electronic                   31.686200              2798.3555   \n",
       "2  Electronic                   11.787950             65289.0160   \n",
       "3  Electronic                    4.609666             60351.8500   \n",
       "4  Electronic                  113.699970             22080.5940   \n",
       "\n",
       "   autocorelation_00_mean  autocorelation_00_median  autocorelation_00_min  \\\n",
       "0                0.010876                 -2.887901             -1593.9122   \n",
       "1                0.002150                 -0.398690             -1224.2454   \n",
       "2                0.065771                 -5.728954            -35123.4340   \n",
       "3                1.028323                 -2.132175            -29979.5370   \n",
       "4               74.396010                 34.283890             -5716.5230   \n",
       "\n",
       "   autocorelation_00_skew  autocorelation_00_std  autocorelation_00_sum  \\\n",
       "0              170.368180               3.016389           7.194268e+03   \n",
       "1               88.129974               0.790848           1.422519e+03   \n",
       "2             4982.006300               0.158547           4.347565e+04   \n",
       "3             5215.574700               0.071497           6.797144e+05   \n",
       "4              437.943730               4.025559           4.917499e+07   \n",
       "\n",
       "   chroma_cens_00_kurtosis  ...  beat_count  dtempo_changes  onset_count  \\\n",
       "0                 1.221379  ...          64               6          169   \n",
       "1                -0.882889  ...          41               5          120   \n",
       "2                -0.937324  ...          66               0          205   \n",
       "3                -0.495610  ...          94              11          211   \n",
       "4                -0.863015  ...          72               9          205   \n",
       "\n",
       "   low_energy_rate  harmonic_to_noise_rate  dynamic_range  swing_ratio  \\\n",
       "0            184.0              -14.303785       0.218490     1.109646   \n",
       "1            364.0                1.258749       0.147046     1.139929   \n",
       "2            278.0                0.197590       0.661439     1.154552   \n",
       "3            191.0                0.258297       0.504590     1.079204   \n",
       "4             88.0                0.470797       0.281950     1.155421   \n",
       "\n",
       "   syncopation    roughness    warmth  \n",
       "0     0.100849   191.356035  0.701712  \n",
       "1     0.312308    57.557036  0.605086  \n",
       "2     0.112588  1374.684072  0.611777  \n",
       "3     0.069990  2111.869221  0.401475  \n",
       "4     0.107491   284.493888  0.461459  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"level_1\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5595, 931) (1199, 931) (1199, 931)\n",
      "(5595,) (1199,) (1199,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df['Genre'] = LabelEncoder().fit_transform(df['Genre'])\n",
    "\n",
    "X = df.drop(\"Genre\", axis=1)\n",
    "y = df[\"Genre\"]\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=42)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, stratify=y_test, test_size=0.5, random_state=42)\n",
    "X_test = sc.transform(X_test)\n",
    "X_valid = sc.transform(X_valid)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_valid.shape)\n",
    "print(y_train.shape, y_test.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "n_classes = 8\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, n_classes)\n",
    "y_valid_encoded = to_categorical(y_valid, n_classes)\n",
    "y_test_encoded = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Input(shape=(931,)))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "175/175 [==============================] - 3s 8ms/step - loss: 3.8793 - accuracy: 0.1253 - val_loss: 2.3424 - val_accuracy: 0.1251\n",
      "Epoch 2/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.8317 - accuracy: 0.1219 - val_loss: 2.3928 - val_accuracy: 0.1251\n",
      "Epoch 3/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.7267 - accuracy: 0.1274 - val_loss: 2.3568 - val_accuracy: 0.1251\n",
      "Epoch 4/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.5348 - accuracy: 0.1278 - val_loss: 2.3179 - val_accuracy: 0.1251\n",
      "Epoch 5/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.4715 - accuracy: 0.1255 - val_loss: 2.2920 - val_accuracy: 0.1251\n",
      "Epoch 6/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.5007 - accuracy: 0.1112 - val_loss: 2.2631 - val_accuracy: 0.1251\n",
      "Epoch 7/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.2884 - accuracy: 0.1274 - val_loss: 2.2381 - val_accuracy: 0.1251\n",
      "Epoch 8/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.2248 - accuracy: 0.1239 - val_loss: 2.2165 - val_accuracy: 0.1251\n",
      "Epoch 9/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.1634 - accuracy: 0.1228 - val_loss: 2.1992 - val_accuracy: 0.1251\n",
      "Epoch 10/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.1086 - accuracy: 0.1296 - val_loss: 2.1808 - val_accuracy: 0.1251\n",
      "Epoch 11/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 3.0188 - accuracy: 0.1280 - val_loss: 2.1680 - val_accuracy: 0.1251\n",
      "Epoch 12/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.9923 - accuracy: 0.1269 - val_loss: 2.1580 - val_accuracy: 0.1251\n",
      "Epoch 13/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.9103 - accuracy: 0.1233 - val_loss: 2.1479 - val_accuracy: 0.1251\n",
      "Epoch 14/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.8440 - accuracy: 0.1351 - val_loss: 2.1419 - val_accuracy: 0.1251\n",
      "Epoch 15/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.7973 - accuracy: 0.1332 - val_loss: 2.1359 - val_accuracy: 0.1259\n",
      "Epoch 16/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.7323 - accuracy: 0.1362 - val_loss: 2.1276 - val_accuracy: 0.1268\n",
      "Epoch 17/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.6988 - accuracy: 0.1274 - val_loss: 2.1192 - val_accuracy: 0.1410\n",
      "Epoch 18/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.6540 - accuracy: 0.1290 - val_loss: 2.1150 - val_accuracy: 0.1284\n",
      "Epoch 19/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.5943 - accuracy: 0.1305 - val_loss: 2.1096 - val_accuracy: 0.1343\n",
      "Epoch 20/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.6058 - accuracy: 0.1194 - val_loss: 2.1067 - val_accuracy: 0.1493\n",
      "Epoch 21/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.5189 - accuracy: 0.1267 - val_loss: 2.1041 - val_accuracy: 0.1384\n",
      "Epoch 22/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.5016 - accuracy: 0.1326 - val_loss: 2.1021 - val_accuracy: 0.1526\n",
      "Epoch 23/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.4677 - accuracy: 0.1273 - val_loss: 2.0995 - val_accuracy: 0.1451\n",
      "Epoch 24/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.4450 - accuracy: 0.1276 - val_loss: 2.0968 - val_accuracy: 0.1368\n",
      "Epoch 25/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3917 - accuracy: 0.1299 - val_loss: 2.0945 - val_accuracy: 0.1460\n",
      "Epoch 26/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.4018 - accuracy: 0.1305 - val_loss: 2.0925 - val_accuracy: 0.1410\n",
      "Epoch 27/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3752 - accuracy: 0.1324 - val_loss: 2.0905 - val_accuracy: 0.1293\n",
      "Epoch 28/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3731 - accuracy: 0.1203 - val_loss: 2.0873 - val_accuracy: 0.1276\n",
      "Epoch 29/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3346 - accuracy: 0.1389 - val_loss: 2.0864 - val_accuracy: 0.1359\n",
      "Epoch 30/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2921 - accuracy: 0.1376 - val_loss: 2.0852 - val_accuracy: 0.1301\n",
      "Epoch 31/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3000 - accuracy: 0.1230 - val_loss: 2.0836 - val_accuracy: 0.1334\n",
      "Epoch 32/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2545 - accuracy: 0.1321 - val_loss: 2.0831 - val_accuracy: 0.1309\n",
      "Epoch 33/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2358 - accuracy: 0.1392 - val_loss: 2.0822 - val_accuracy: 0.1301\n",
      "Epoch 34/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2329 - accuracy: 0.1349 - val_loss: 2.0807 - val_accuracy: 0.1301\n",
      "Epoch 35/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2163 - accuracy: 0.1367 - val_loss: 2.0797 - val_accuracy: 0.1384\n",
      "Epoch 36/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2049 - accuracy: 0.1344 - val_loss: 2.0790 - val_accuracy: 0.1526\n",
      "Epoch 37/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1842 - accuracy: 0.1482 - val_loss: 2.0783 - val_accuracy: 0.1560\n",
      "Epoch 38/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1849 - accuracy: 0.1426 - val_loss: 2.0770 - val_accuracy: 0.1543\n",
      "Epoch 39/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1776 - accuracy: 0.1396 - val_loss: 2.0762 - val_accuracy: 0.1535\n",
      "Epoch 40/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1633 - accuracy: 0.1391 - val_loss: 2.0760 - val_accuracy: 0.1368\n",
      "Epoch 41/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1557 - accuracy: 0.1426 - val_loss: 2.0758 - val_accuracy: 0.1301\n",
      "Epoch 42/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1519 - accuracy: 0.1374 - val_loss: 2.0740 - val_accuracy: 0.1318\n",
      "Epoch 43/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1471 - accuracy: 0.1324 - val_loss: 2.0734 - val_accuracy: 0.1343\n",
      "Epoch 44/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1460 - accuracy: 0.1305 - val_loss: 2.0723 - val_accuracy: 0.1393\n",
      "Epoch 45/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1274 - accuracy: 0.1385 - val_loss: 2.0696 - val_accuracy: 0.1560\n",
      "Epoch 46/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.1176 - accuracy: 0.1514 - val_loss: 2.0698 - val_accuracy: 0.1610\n",
      "Epoch 47/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1111 - accuracy: 0.1514 - val_loss: 2.0673 - val_accuracy: 0.1551\n",
      "Epoch 48/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1030 - accuracy: 0.1498 - val_loss: 2.0651 - val_accuracy: 0.1543\n",
      "Epoch 49/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1008 - accuracy: 0.1508 - val_loss: 2.0639 - val_accuracy: 0.1601\n",
      "Epoch 50/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0893 - accuracy: 0.1487 - val_loss: 2.0613 - val_accuracy: 0.1743\n",
      "Epoch 51/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0934 - accuracy: 0.1458 - val_loss: 2.0616 - val_accuracy: 0.1793\n",
      "Epoch 52/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0889 - accuracy: 0.1541 - val_loss: 2.0588 - val_accuracy: 0.1751\n",
      "Epoch 53/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0795 - accuracy: 0.1576 - val_loss: 2.0538 - val_accuracy: 0.1902\n",
      "Epoch 54/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0691 - accuracy: 0.1614 - val_loss: 2.0511 - val_accuracy: 0.1943\n",
      "Epoch 55/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0753 - accuracy: 0.1569 - val_loss: 2.0501 - val_accuracy: 0.1952\n",
      "Epoch 56/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0584 - accuracy: 0.1594 - val_loss: 2.0469 - val_accuracy: 0.2027\n",
      "Epoch 57/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0622 - accuracy: 0.1616 - val_loss: 2.0451 - val_accuracy: 0.2018\n",
      "Epoch 58/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0562 - accuracy: 0.1673 - val_loss: 2.0415 - val_accuracy: 0.2085\n",
      "Epoch 59/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0577 - accuracy: 0.1668 - val_loss: 2.0366 - val_accuracy: 0.2127\n",
      "Epoch 60/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0486 - accuracy: 0.1666 - val_loss: 2.0341 - val_accuracy: 0.2185\n",
      "Epoch 61/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0469 - accuracy: 0.1666 - val_loss: 2.0306 - val_accuracy: 0.2193\n",
      "Epoch 62/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0424 - accuracy: 0.1673 - val_loss: 2.0249 - val_accuracy: 0.2560\n",
      "Epoch 63/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0313 - accuracy: 0.1832 - val_loss: 2.0219 - val_accuracy: 0.2661\n",
      "Epoch 64/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0328 - accuracy: 0.1769 - val_loss: 2.0149 - val_accuracy: 0.2694\n",
      "Epoch 65/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0305 - accuracy: 0.1753 - val_loss: 2.0109 - val_accuracy: 0.2811\n",
      "Epoch 66/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0205 - accuracy: 0.1905 - val_loss: 2.0047 - val_accuracy: 0.2894\n",
      "Epoch 67/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0181 - accuracy: 0.1882 - val_loss: 2.0019 - val_accuracy: 0.2894\n",
      "Epoch 68/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0167 - accuracy: 0.1936 - val_loss: 1.9936 - val_accuracy: 0.2919\n",
      "Epoch 69/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 2.0082 - accuracy: 0.2004 - val_loss: 1.9855 - val_accuracy: 0.2986\n",
      "Epoch 70/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9960 - accuracy: 0.2104 - val_loss: 1.9787 - val_accuracy: 0.3003\n",
      "Epoch 71/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9921 - accuracy: 0.2088 - val_loss: 1.9710 - val_accuracy: 0.3028\n",
      "Epoch 72/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9907 - accuracy: 0.2089 - val_loss: 1.9639 - val_accuracy: 0.3061\n",
      "Epoch 73/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9859 - accuracy: 0.2127 - val_loss: 1.9565 - val_accuracy: 0.3028\n",
      "Epoch 74/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9722 - accuracy: 0.2238 - val_loss: 1.9437 - val_accuracy: 0.3069\n",
      "Epoch 75/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9653 - accuracy: 0.2302 - val_loss: 1.9337 - val_accuracy: 0.3078\n",
      "Epoch 76/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9559 - accuracy: 0.2354 - val_loss: 1.9214 - val_accuracy: 0.3078\n",
      "Epoch 77/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9563 - accuracy: 0.2304 - val_loss: 1.9141 - val_accuracy: 0.3119\n",
      "Epoch 78/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9506 - accuracy: 0.2440 - val_loss: 1.8988 - val_accuracy: 0.3061\n",
      "Epoch 79/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9418 - accuracy: 0.2536 - val_loss: 1.8859 - val_accuracy: 0.3086\n",
      "Epoch 80/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9295 - accuracy: 0.2549 - val_loss: 1.8756 - val_accuracy: 0.3078\n",
      "Epoch 81/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9199 - accuracy: 0.2490 - val_loss: 1.8562 - val_accuracy: 0.3103\n",
      "Epoch 82/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9124 - accuracy: 0.2556 - val_loss: 1.8456 - val_accuracy: 0.3128\n",
      "Epoch 83/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.9128 - accuracy: 0.2690 - val_loss: 1.8323 - val_accuracy: 0.3186\n",
      "Epoch 84/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8990 - accuracy: 0.2634 - val_loss: 1.8209 - val_accuracy: 0.3203\n",
      "Epoch 85/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8935 - accuracy: 0.2647 - val_loss: 1.8149 - val_accuracy: 0.3228\n",
      "Epoch 86/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8903 - accuracy: 0.2683 - val_loss: 1.8081 - val_accuracy: 0.3244\n",
      "Epoch 87/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8765 - accuracy: 0.2758 - val_loss: 1.7980 - val_accuracy: 0.3294\n",
      "Epoch 88/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8788 - accuracy: 0.2770 - val_loss: 1.7895 - val_accuracy: 0.3344\n",
      "Epoch 89/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8628 - accuracy: 0.2929 - val_loss: 1.7816 - val_accuracy: 0.3344\n",
      "Epoch 90/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8608 - accuracy: 0.2919 - val_loss: 1.7707 - val_accuracy: 0.3386\n",
      "Epoch 91/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8591 - accuracy: 0.2854 - val_loss: 1.7625 - val_accuracy: 0.3378\n",
      "Epoch 92/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8543 - accuracy: 0.2972 - val_loss: 1.7550 - val_accuracy: 0.3353\n",
      "Epoch 93/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8494 - accuracy: 0.3010 - val_loss: 1.7537 - val_accuracy: 0.3428\n",
      "Epoch 94/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8318 - accuracy: 0.3004 - val_loss: 1.7462 - val_accuracy: 0.3445\n",
      "Epoch 95/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8393 - accuracy: 0.2978 - val_loss: 1.7392 - val_accuracy: 0.3428\n",
      "Epoch 96/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8321 - accuracy: 0.2962 - val_loss: 1.7290 - val_accuracy: 0.3470\n",
      "Epoch 97/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8352 - accuracy: 0.2988 - val_loss: 1.7267 - val_accuracy: 0.3486\n",
      "Epoch 98/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8141 - accuracy: 0.3122 - val_loss: 1.7243 - val_accuracy: 0.3495\n",
      "Epoch 99/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8170 - accuracy: 0.3144 - val_loss: 1.7205 - val_accuracy: 0.3528\n",
      "Epoch 100/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8116 - accuracy: 0.3151 - val_loss: 1.7139 - val_accuracy: 0.3570\n",
      "Epoch 101/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8125 - accuracy: 0.3024 - val_loss: 1.7049 - val_accuracy: 0.3595\n",
      "Epoch 102/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8119 - accuracy: 0.3121 - val_loss: 1.7050 - val_accuracy: 0.3670\n",
      "Epoch 103/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7997 - accuracy: 0.3112 - val_loss: 1.6975 - val_accuracy: 0.3645\n",
      "Epoch 104/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.8020 - accuracy: 0.3165 - val_loss: 1.6921 - val_accuracy: 0.3711\n",
      "Epoch 105/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7942 - accuracy: 0.3160 - val_loss: 1.6837 - val_accuracy: 0.3670\n",
      "Epoch 106/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7840 - accuracy: 0.3156 - val_loss: 1.6807 - val_accuracy: 0.3728\n",
      "Epoch 107/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7829 - accuracy: 0.3237 - val_loss: 1.6809 - val_accuracy: 0.3703\n",
      "Epoch 108/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7822 - accuracy: 0.3242 - val_loss: 1.6744 - val_accuracy: 0.3720\n",
      "Epoch 109/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7659 - accuracy: 0.3269 - val_loss: 1.6731 - val_accuracy: 0.3753\n",
      "Epoch 110/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7801 - accuracy: 0.3244 - val_loss: 1.6712 - val_accuracy: 0.3720\n",
      "Epoch 111/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7646 - accuracy: 0.3242 - val_loss: 1.6656 - val_accuracy: 0.3745\n",
      "Epoch 112/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7674 - accuracy: 0.3262 - val_loss: 1.6600 - val_accuracy: 0.3711\n",
      "Epoch 113/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7525 - accuracy: 0.3339 - val_loss: 1.6511 - val_accuracy: 0.3778\n",
      "Epoch 114/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7527 - accuracy: 0.3367 - val_loss: 1.6515 - val_accuracy: 0.3770\n",
      "Epoch 115/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7608 - accuracy: 0.3369 - val_loss: 1.6461 - val_accuracy: 0.3845\n",
      "Epoch 116/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7465 - accuracy: 0.3367 - val_loss: 1.6421 - val_accuracy: 0.3828\n",
      "Epoch 117/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7442 - accuracy: 0.3328 - val_loss: 1.6431 - val_accuracy: 0.3845\n",
      "Epoch 118/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7247 - accuracy: 0.3466 - val_loss: 1.6372 - val_accuracy: 0.3903\n",
      "Epoch 119/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7365 - accuracy: 0.3346 - val_loss: 1.6364 - val_accuracy: 0.3887\n",
      "Epoch 120/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7296 - accuracy: 0.3412 - val_loss: 1.6283 - val_accuracy: 0.3912\n",
      "Epoch 121/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7334 - accuracy: 0.3421 - val_loss: 1.6298 - val_accuracy: 0.3928\n",
      "Epoch 122/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7182 - accuracy: 0.3412 - val_loss: 1.6276 - val_accuracy: 0.3870\n",
      "Epoch 123/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7209 - accuracy: 0.3457 - val_loss: 1.6203 - val_accuracy: 0.3962\n",
      "Epoch 124/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7132 - accuracy: 0.3407 - val_loss: 1.6236 - val_accuracy: 0.3987\n",
      "Epoch 125/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7111 - accuracy: 0.3555 - val_loss: 1.6167 - val_accuracy: 0.4003\n",
      "Epoch 126/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.7081 - accuracy: 0.3616 - val_loss: 1.6110 - val_accuracy: 0.4087\n",
      "Epoch 127/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6954 - accuracy: 0.3546 - val_loss: 1.6071 - val_accuracy: 0.4020\n",
      "Epoch 128/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7033 - accuracy: 0.3496 - val_loss: 1.6029 - val_accuracy: 0.4028\n",
      "Epoch 129/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.7093 - accuracy: 0.3500 - val_loss: 1.6016 - val_accuracy: 0.4020\n",
      "Epoch 130/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6889 - accuracy: 0.3546 - val_loss: 1.5986 - val_accuracy: 0.4020\n",
      "Epoch 131/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6789 - accuracy: 0.3535 - val_loss: 1.5972 - val_accuracy: 0.4003\n",
      "Epoch 132/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6884 - accuracy: 0.3680 - val_loss: 1.5925 - val_accuracy: 0.4037\n",
      "Epoch 133/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6845 - accuracy: 0.3614 - val_loss: 1.5911 - val_accuracy: 0.4112\n",
      "Epoch 134/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6778 - accuracy: 0.3560 - val_loss: 1.5846 - val_accuracy: 0.4170\n",
      "Epoch 135/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6773 - accuracy: 0.3666 - val_loss: 1.5801 - val_accuracy: 0.4120\n",
      "Epoch 136/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6614 - accuracy: 0.3660 - val_loss: 1.5782 - val_accuracy: 0.4112\n",
      "Epoch 137/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6758 - accuracy: 0.3723 - val_loss: 1.5839 - val_accuracy: 0.4195\n",
      "Epoch 138/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6767 - accuracy: 0.3534 - val_loss: 1.5800 - val_accuracy: 0.4162\n",
      "Epoch 139/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6641 - accuracy: 0.3660 - val_loss: 1.5714 - val_accuracy: 0.4162\n",
      "Epoch 140/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6663 - accuracy: 0.3676 - val_loss: 1.5797 - val_accuracy: 0.4145\n",
      "Epoch 141/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6538 - accuracy: 0.3653 - val_loss: 1.5679 - val_accuracy: 0.4212\n",
      "Epoch 142/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6429 - accuracy: 0.3698 - val_loss: 1.5691 - val_accuracy: 0.4204\n",
      "Epoch 143/800\n",
      "175/175 [==============================] - 1s 8ms/step - loss: 1.6610 - accuracy: 0.3773 - val_loss: 1.5688 - val_accuracy: 0.4220\n",
      "Epoch 144/800\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.6476 - accuracy: 0.3716 - val_loss: 1.5604 - val_accuracy: 0.4204\n",
      "Epoch 145/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6508 - accuracy: 0.3784 - val_loss: 1.5639 - val_accuracy: 0.4254\n",
      "Epoch 146/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6479 - accuracy: 0.3843 - val_loss: 1.5583 - val_accuracy: 0.4229\n",
      "Epoch 147/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6337 - accuracy: 0.3884 - val_loss: 1.5523 - val_accuracy: 0.4287\n",
      "Epoch 148/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6397 - accuracy: 0.3764 - val_loss: 1.5485 - val_accuracy: 0.4245\n",
      "Epoch 149/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6433 - accuracy: 0.3837 - val_loss: 1.5492 - val_accuracy: 0.4345\n",
      "Epoch 150/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6190 - accuracy: 0.3914 - val_loss: 1.5501 - val_accuracy: 0.4354\n",
      "Epoch 151/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6367 - accuracy: 0.3782 - val_loss: 1.5482 - val_accuracy: 0.4270\n",
      "Epoch 152/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6246 - accuracy: 0.3807 - val_loss: 1.5551 - val_accuracy: 0.4304\n",
      "Epoch 153/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6261 - accuracy: 0.3780 - val_loss: 1.5479 - val_accuracy: 0.4345\n",
      "Epoch 154/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6034 - accuracy: 0.3834 - val_loss: 1.5507 - val_accuracy: 0.4412\n",
      "Epoch 155/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6050 - accuracy: 0.3864 - val_loss: 1.5472 - val_accuracy: 0.4354\n",
      "Epoch 156/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5987 - accuracy: 0.3918 - val_loss: 1.5410 - val_accuracy: 0.4387\n",
      "Epoch 157/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6122 - accuracy: 0.3923 - val_loss: 1.5393 - val_accuracy: 0.4404\n",
      "Epoch 158/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5937 - accuracy: 0.3975 - val_loss: 1.5427 - val_accuracy: 0.4345\n",
      "Epoch 159/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5884 - accuracy: 0.3961 - val_loss: 1.5448 - val_accuracy: 0.4387\n",
      "Epoch 160/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6040 - accuracy: 0.3937 - val_loss: 1.5386 - val_accuracy: 0.4379\n",
      "Epoch 161/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5944 - accuracy: 0.3943 - val_loss: 1.5437 - val_accuracy: 0.4395\n",
      "Epoch 162/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5950 - accuracy: 0.3948 - val_loss: 1.5433 - val_accuracy: 0.4370\n",
      "Epoch 163/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.6000 - accuracy: 0.3962 - val_loss: 1.5377 - val_accuracy: 0.4395\n",
      "Epoch 164/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4004 - val_loss: 1.5359 - val_accuracy: 0.4404\n",
      "Epoch 165/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5807 - accuracy: 0.4045 - val_loss: 1.5263 - val_accuracy: 0.4454\n",
      "Epoch 166/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5835 - accuracy: 0.3950 - val_loss: 1.5315 - val_accuracy: 0.4470\n",
      "Epoch 167/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5736 - accuracy: 0.4048 - val_loss: 1.5269 - val_accuracy: 0.4462\n",
      "Epoch 168/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5741 - accuracy: 0.3975 - val_loss: 1.5302 - val_accuracy: 0.4454\n",
      "Epoch 169/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5565 - accuracy: 0.4059 - val_loss: 1.5249 - val_accuracy: 0.4529\n",
      "Epoch 170/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5552 - accuracy: 0.4197 - val_loss: 1.5244 - val_accuracy: 0.4529\n",
      "Epoch 171/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5727 - accuracy: 0.4030 - val_loss: 1.5252 - val_accuracy: 0.4537\n",
      "Epoch 172/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5661 - accuracy: 0.4104 - val_loss: 1.5173 - val_accuracy: 0.4579\n",
      "Epoch 173/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5493 - accuracy: 0.4143 - val_loss: 1.5161 - val_accuracy: 0.4654\n",
      "Epoch 174/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5500 - accuracy: 0.4168 - val_loss: 1.5192 - val_accuracy: 0.4595\n",
      "Epoch 175/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5373 - accuracy: 0.4218 - val_loss: 1.5224 - val_accuracy: 0.4587\n",
      "Epoch 176/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5456 - accuracy: 0.4116 - val_loss: 1.5135 - val_accuracy: 0.4621\n",
      "Epoch 177/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5413 - accuracy: 0.4236 - val_loss: 1.5144 - val_accuracy: 0.4662\n",
      "Epoch 178/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5256 - accuracy: 0.4163 - val_loss: 1.5154 - val_accuracy: 0.4637\n",
      "Epoch 179/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5398 - accuracy: 0.4213 - val_loss: 1.5193 - val_accuracy: 0.4629\n",
      "Epoch 180/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5349 - accuracy: 0.4170 - val_loss: 1.5127 - val_accuracy: 0.4704\n",
      "Epoch 181/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5455 - accuracy: 0.4236 - val_loss: 1.5125 - val_accuracy: 0.4637\n",
      "Epoch 182/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5316 - accuracy: 0.4254 - val_loss: 1.5039 - val_accuracy: 0.4662\n",
      "Epoch 183/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5271 - accuracy: 0.4239 - val_loss: 1.5111 - val_accuracy: 0.4679\n",
      "Epoch 184/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5187 - accuracy: 0.4293 - val_loss: 1.5140 - val_accuracy: 0.4579\n",
      "Epoch 185/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5158 - accuracy: 0.4286 - val_loss: 1.5137 - val_accuracy: 0.4587\n",
      "Epoch 186/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5049 - accuracy: 0.4309 - val_loss: 1.5113 - val_accuracy: 0.4629\n",
      "Epoch 187/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5308 - accuracy: 0.4252 - val_loss: 1.5049 - val_accuracy: 0.4629\n",
      "Epoch 188/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5169 - accuracy: 0.4327 - val_loss: 1.5002 - val_accuracy: 0.4687\n",
      "Epoch 189/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5282 - accuracy: 0.4263 - val_loss: 1.4999 - val_accuracy: 0.4746\n",
      "Epoch 190/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5223 - accuracy: 0.4311 - val_loss: 1.5014 - val_accuracy: 0.4737\n",
      "Epoch 191/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5165 - accuracy: 0.4343 - val_loss: 1.4986 - val_accuracy: 0.4621\n",
      "Epoch 192/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5102 - accuracy: 0.4329 - val_loss: 1.5024 - val_accuracy: 0.4629\n",
      "Epoch 193/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5048 - accuracy: 0.4327 - val_loss: 1.5007 - val_accuracy: 0.4671\n",
      "Epoch 194/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4998 - accuracy: 0.4377 - val_loss: 1.4963 - val_accuracy: 0.4671\n",
      "Epoch 195/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4922 - accuracy: 0.4429 - val_loss: 1.5046 - val_accuracy: 0.4646\n",
      "Epoch 196/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.5185 - accuracy: 0.4309 - val_loss: 1.4857 - val_accuracy: 0.4737\n",
      "Epoch 197/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.5022 - accuracy: 0.4361 - val_loss: 1.4876 - val_accuracy: 0.4829\n",
      "Epoch 198/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4865 - accuracy: 0.4477 - val_loss: 1.4897 - val_accuracy: 0.4754\n",
      "Epoch 199/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4737 - accuracy: 0.4508 - val_loss: 1.4853 - val_accuracy: 0.4746\n",
      "Epoch 200/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4861 - accuracy: 0.4388 - val_loss: 1.4887 - val_accuracy: 0.4671\n",
      "Epoch 201/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4893 - accuracy: 0.4508 - val_loss: 1.4789 - val_accuracy: 0.4721\n",
      "Epoch 202/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4763 - accuracy: 0.4481 - val_loss: 1.4761 - val_accuracy: 0.4754\n",
      "Epoch 203/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4797 - accuracy: 0.4456 - val_loss: 1.4816 - val_accuracy: 0.4796\n",
      "Epoch 204/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4874 - accuracy: 0.4484 - val_loss: 1.4799 - val_accuracy: 0.4704\n",
      "Epoch 205/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4813 - accuracy: 0.4441 - val_loss: 1.4825 - val_accuracy: 0.4754\n",
      "Epoch 206/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4643 - accuracy: 0.4520 - val_loss: 1.4767 - val_accuracy: 0.4837\n",
      "Epoch 207/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4574 - accuracy: 0.4466 - val_loss: 1.4765 - val_accuracy: 0.4829\n",
      "Epoch 208/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4473 - accuracy: 0.4525 - val_loss: 1.4758 - val_accuracy: 0.4704\n",
      "Epoch 209/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4666 - accuracy: 0.4450 - val_loss: 1.4615 - val_accuracy: 0.4729\n",
      "Epoch 210/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4452 - accuracy: 0.4540 - val_loss: 1.4761 - val_accuracy: 0.4812\n",
      "Epoch 211/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4631 - accuracy: 0.4542 - val_loss: 1.4698 - val_accuracy: 0.4796\n",
      "Epoch 212/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4597 - accuracy: 0.4550 - val_loss: 1.4747 - val_accuracy: 0.4829\n",
      "Epoch 213/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4533 - accuracy: 0.4552 - val_loss: 1.4768 - val_accuracy: 0.4812\n",
      "Epoch 214/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4482 - accuracy: 0.4586 - val_loss: 1.4739 - val_accuracy: 0.4829\n",
      "Epoch 215/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4549 - accuracy: 0.4545 - val_loss: 1.4713 - val_accuracy: 0.4904\n",
      "Epoch 216/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4353 - accuracy: 0.4627 - val_loss: 1.4673 - val_accuracy: 0.4771\n",
      "Epoch 217/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4429 - accuracy: 0.4670 - val_loss: 1.4627 - val_accuracy: 0.4829\n",
      "Epoch 218/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4430 - accuracy: 0.4584 - val_loss: 1.4621 - val_accuracy: 0.4821\n",
      "Epoch 219/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4429 - accuracy: 0.4642 - val_loss: 1.4662 - val_accuracy: 0.4829\n",
      "Epoch 220/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4360 - accuracy: 0.4679 - val_loss: 1.4756 - val_accuracy: 0.4779\n",
      "Epoch 221/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4338 - accuracy: 0.4620 - val_loss: 1.4710 - val_accuracy: 0.4796\n",
      "Epoch 222/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4503 - accuracy: 0.4567 - val_loss: 1.4609 - val_accuracy: 0.4812\n",
      "Epoch 223/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4440 - accuracy: 0.4649 - val_loss: 1.4690 - val_accuracy: 0.4754\n",
      "Epoch 224/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4303 - accuracy: 0.4704 - val_loss: 1.4715 - val_accuracy: 0.4879\n",
      "Epoch 225/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4343 - accuracy: 0.4534 - val_loss: 1.4774 - val_accuracy: 0.4829\n",
      "Epoch 226/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4132 - accuracy: 0.4692 - val_loss: 1.4751 - val_accuracy: 0.4854\n",
      "Epoch 227/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4120 - accuracy: 0.4702 - val_loss: 1.4682 - val_accuracy: 0.4871\n",
      "Epoch 228/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3939 - accuracy: 0.4840 - val_loss: 1.4678 - val_accuracy: 0.4854\n",
      "Epoch 229/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4230 - accuracy: 0.4685 - val_loss: 1.4866 - val_accuracy: 0.4879\n",
      "Epoch 230/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4258 - accuracy: 0.4568 - val_loss: 1.4731 - val_accuracy: 0.4804\n",
      "Epoch 231/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4020 - accuracy: 0.4792 - val_loss: 1.4639 - val_accuracy: 0.4846\n",
      "Epoch 232/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.4005 - accuracy: 0.4785 - val_loss: 1.4727 - val_accuracy: 0.4762\n",
      "Epoch 233/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4017 - accuracy: 0.4815 - val_loss: 1.4673 - val_accuracy: 0.4871\n",
      "Epoch 234/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4102 - accuracy: 0.4720 - val_loss: 1.4655 - val_accuracy: 0.4887\n",
      "Epoch 235/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4166 - accuracy: 0.4736 - val_loss: 1.4624 - val_accuracy: 0.4904\n",
      "Epoch 236/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3941 - accuracy: 0.4820 - val_loss: 1.4616 - val_accuracy: 0.4887\n",
      "Epoch 237/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3960 - accuracy: 0.4720 - val_loss: 1.4623 - val_accuracy: 0.4929\n",
      "Epoch 238/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3925 - accuracy: 0.4713 - val_loss: 1.4533 - val_accuracy: 0.4921\n",
      "Epoch 239/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3959 - accuracy: 0.4849 - val_loss: 1.4548 - val_accuracy: 0.4904\n",
      "Epoch 240/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4034 - accuracy: 0.4758 - val_loss: 1.4601 - val_accuracy: 0.4971\n",
      "Epoch 241/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3717 - accuracy: 0.4920 - val_loss: 1.4585 - val_accuracy: 0.5013\n",
      "Epoch 242/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3834 - accuracy: 0.4942 - val_loss: 1.4630 - val_accuracy: 0.4962\n",
      "Epoch 243/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3852 - accuracy: 0.4724 - val_loss: 1.4577 - val_accuracy: 0.5021\n",
      "Epoch 244/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3794 - accuracy: 0.4845 - val_loss: 1.4588 - val_accuracy: 0.4954\n",
      "Epoch 245/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3688 - accuracy: 0.4826 - val_loss: 1.4642 - val_accuracy: 0.4971\n",
      "Epoch 246/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3793 - accuracy: 0.4820 - val_loss: 1.4581 - val_accuracy: 0.4987\n",
      "Epoch 247/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.4034 - accuracy: 0.4870 - val_loss: 1.4607 - val_accuracy: 0.4912\n",
      "Epoch 248/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3705 - accuracy: 0.4858 - val_loss: 1.4539 - val_accuracy: 0.4946\n",
      "Epoch 249/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3803 - accuracy: 0.4861 - val_loss: 1.4369 - val_accuracy: 0.4979\n",
      "Epoch 250/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3855 - accuracy: 0.4858 - val_loss: 1.4520 - val_accuracy: 0.4971\n",
      "Epoch 251/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3702 - accuracy: 0.4795 - val_loss: 1.4529 - val_accuracy: 0.5013\n",
      "Epoch 252/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3391 - accuracy: 0.5085 - val_loss: 1.4491 - val_accuracy: 0.5054\n",
      "Epoch 253/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3682 - accuracy: 0.4849 - val_loss: 1.4481 - val_accuracy: 0.5021\n",
      "Epoch 254/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3678 - accuracy: 0.4885 - val_loss: 1.4390 - val_accuracy: 0.5021\n",
      "Epoch 255/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3583 - accuracy: 0.4976 - val_loss: 1.4415 - val_accuracy: 0.5054\n",
      "Epoch 256/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3563 - accuracy: 0.4879 - val_loss: 1.4493 - val_accuracy: 0.5121\n",
      "Epoch 257/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3606 - accuracy: 0.4979 - val_loss: 1.4401 - val_accuracy: 0.5071\n",
      "Epoch 258/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3362 - accuracy: 0.5062 - val_loss: 1.4466 - val_accuracy: 0.4962\n",
      "Epoch 259/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3567 - accuracy: 0.4874 - val_loss: 1.4426 - val_accuracy: 0.5079\n",
      "Epoch 260/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3530 - accuracy: 0.4972 - val_loss: 1.4333 - val_accuracy: 0.5079\n",
      "Epoch 261/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3601 - accuracy: 0.4956 - val_loss: 1.4375 - val_accuracy: 0.5038\n",
      "Epoch 262/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3626 - accuracy: 0.4870 - val_loss: 1.4378 - val_accuracy: 0.5021\n",
      "Epoch 263/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3432 - accuracy: 0.5058 - val_loss: 1.4269 - val_accuracy: 0.5038\n",
      "Epoch 264/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3502 - accuracy: 0.4951 - val_loss: 1.4217 - val_accuracy: 0.5171\n",
      "Epoch 265/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3337 - accuracy: 0.5049 - val_loss: 1.4429 - val_accuracy: 0.5129\n",
      "Epoch 266/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3447 - accuracy: 0.4981 - val_loss: 1.4414 - val_accuracy: 0.5054\n",
      "Epoch 267/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3229 - accuracy: 0.4967 - val_loss: 1.4310 - val_accuracy: 0.5029\n",
      "Epoch 268/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3141 - accuracy: 0.5121 - val_loss: 1.4302 - val_accuracy: 0.5088\n",
      "Epoch 269/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3327 - accuracy: 0.5055 - val_loss: 1.4265 - val_accuracy: 0.5054\n",
      "Epoch 270/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3222 - accuracy: 0.5029 - val_loss: 1.4315 - val_accuracy: 0.5079\n",
      "Epoch 271/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3153 - accuracy: 0.5060 - val_loss: 1.4325 - val_accuracy: 0.5238\n",
      "Epoch 272/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3174 - accuracy: 0.5072 - val_loss: 1.4365 - val_accuracy: 0.5163\n",
      "Epoch 273/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3227 - accuracy: 0.5097 - val_loss: 1.4314 - val_accuracy: 0.5238\n",
      "Epoch 274/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3220 - accuracy: 0.5037 - val_loss: 1.4292 - val_accuracy: 0.5204\n",
      "Epoch 275/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3318 - accuracy: 0.5110 - val_loss: 1.4313 - val_accuracy: 0.5096\n",
      "Epoch 276/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3191 - accuracy: 0.5081 - val_loss: 1.4260 - val_accuracy: 0.5146\n",
      "Epoch 277/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3013 - accuracy: 0.5139 - val_loss: 1.4195 - val_accuracy: 0.5146\n",
      "Epoch 278/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3201 - accuracy: 0.5074 - val_loss: 1.4187 - val_accuracy: 0.5088\n",
      "Epoch 279/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3038 - accuracy: 0.5094 - val_loss: 1.4195 - val_accuracy: 0.5029\n",
      "Epoch 280/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3004 - accuracy: 0.5099 - val_loss: 1.4317 - val_accuracy: 0.5071\n",
      "Epoch 281/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2999 - accuracy: 0.5147 - val_loss: 1.4276 - val_accuracy: 0.5129\n",
      "Epoch 282/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3088 - accuracy: 0.5124 - val_loss: 1.4215 - val_accuracy: 0.5188\n",
      "Epoch 283/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3201 - accuracy: 0.5069 - val_loss: 1.4335 - val_accuracy: 0.5096\n",
      "Epoch 284/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.3151 - accuracy: 0.5169 - val_loss: 1.4456 - val_accuracy: 0.5046\n",
      "Epoch 285/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2968 - accuracy: 0.5156 - val_loss: 1.4304 - val_accuracy: 0.5129\n",
      "Epoch 286/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3061 - accuracy: 0.5149 - val_loss: 1.4367 - val_accuracy: 0.5121\n",
      "Epoch 287/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2953 - accuracy: 0.5113 - val_loss: 1.4470 - val_accuracy: 0.5079\n",
      "Epoch 288/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2924 - accuracy: 0.5203 - val_loss: 1.4334 - val_accuracy: 0.5129\n",
      "Epoch 289/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3043 - accuracy: 0.5178 - val_loss: 1.4362 - val_accuracy: 0.5196\n",
      "Epoch 290/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2867 - accuracy: 0.5253 - val_loss: 1.4382 - val_accuracy: 0.5054\n",
      "Epoch 291/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.3174 - accuracy: 0.5115 - val_loss: 1.4387 - val_accuracy: 0.5196\n",
      "Epoch 292/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2677 - accuracy: 0.5315 - val_loss: 1.4363 - val_accuracy: 0.5196\n",
      "Epoch 293/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2923 - accuracy: 0.5178 - val_loss: 1.4475 - val_accuracy: 0.5188\n",
      "Epoch 294/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2782 - accuracy: 0.5312 - val_loss: 1.4288 - val_accuracy: 0.5229\n",
      "Epoch 295/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2912 - accuracy: 0.5290 - val_loss: 1.4385 - val_accuracy: 0.5188\n",
      "Epoch 296/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2835 - accuracy: 0.5274 - val_loss: 1.4325 - val_accuracy: 0.5171\n",
      "Epoch 297/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2866 - accuracy: 0.5276 - val_loss: 1.4286 - val_accuracy: 0.5129\n",
      "Epoch 298/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2658 - accuracy: 0.5244 - val_loss: 1.4233 - val_accuracy: 0.5179\n",
      "Epoch 299/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2506 - accuracy: 0.5307 - val_loss: 1.4237 - val_accuracy: 0.5196\n",
      "Epoch 300/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2744 - accuracy: 0.5273 - val_loss: 1.4280 - val_accuracy: 0.5221\n",
      "Epoch 301/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2555 - accuracy: 0.5239 - val_loss: 1.4236 - val_accuracy: 0.5196\n",
      "Epoch 302/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2507 - accuracy: 0.5444 - val_loss: 1.4226 - val_accuracy: 0.5246\n",
      "Epoch 303/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2692 - accuracy: 0.5369 - val_loss: 1.4287 - val_accuracy: 0.5229\n",
      "Epoch 304/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2606 - accuracy: 0.5335 - val_loss: 1.4297 - val_accuracy: 0.5254\n",
      "Epoch 305/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2984 - accuracy: 0.5271 - val_loss: 1.4244 - val_accuracy: 0.5196\n",
      "Epoch 306/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2520 - accuracy: 0.5351 - val_loss: 1.4134 - val_accuracy: 0.5246\n",
      "Epoch 307/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2882 - accuracy: 0.5199 - val_loss: 1.4107 - val_accuracy: 0.5313\n",
      "Epoch 308/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2544 - accuracy: 0.5383 - val_loss: 1.4218 - val_accuracy: 0.5254\n",
      "Epoch 309/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2638 - accuracy: 0.5296 - val_loss: 1.4241 - val_accuracy: 0.5238\n",
      "Epoch 310/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2459 - accuracy: 0.5383 - val_loss: 1.4219 - val_accuracy: 0.5246\n",
      "Epoch 311/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2706 - accuracy: 0.5417 - val_loss: 1.4175 - val_accuracy: 0.5204\n",
      "Epoch 312/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2404 - accuracy: 0.5423 - val_loss: 1.4140 - val_accuracy: 0.5313\n",
      "Epoch 313/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2794 - accuracy: 0.5340 - val_loss: 1.4206 - val_accuracy: 0.5354\n",
      "Epoch 314/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2564 - accuracy: 0.5423 - val_loss: 1.4270 - val_accuracy: 0.5238\n",
      "Epoch 315/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2183 - accuracy: 0.5444 - val_loss: 1.4271 - val_accuracy: 0.5313\n",
      "Epoch 316/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2278 - accuracy: 0.5491 - val_loss: 1.4277 - val_accuracy: 0.5196\n",
      "Epoch 317/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2412 - accuracy: 0.5451 - val_loss: 1.4201 - val_accuracy: 0.5196\n",
      "Epoch 318/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2417 - accuracy: 0.5442 - val_loss: 1.4180 - val_accuracy: 0.5263\n",
      "Epoch 319/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2402 - accuracy: 0.5446 - val_loss: 1.4125 - val_accuracy: 0.5321\n",
      "Epoch 320/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2664 - accuracy: 0.5314 - val_loss: 1.4243 - val_accuracy: 0.5213\n",
      "Epoch 321/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2303 - accuracy: 0.5421 - val_loss: 1.4341 - val_accuracy: 0.5296\n",
      "Epoch 322/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2501 - accuracy: 0.5398 - val_loss: 1.4357 - val_accuracy: 0.5254\n",
      "Epoch 323/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2412 - accuracy: 0.5351 - val_loss: 1.4247 - val_accuracy: 0.5296\n",
      "Epoch 324/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2364 - accuracy: 0.5530 - val_loss: 1.4184 - val_accuracy: 0.5288\n",
      "Epoch 325/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2504 - accuracy: 0.5349 - val_loss: 1.4237 - val_accuracy: 0.5246\n",
      "Epoch 326/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2289 - accuracy: 0.5424 - val_loss: 1.4058 - val_accuracy: 0.5279\n",
      "Epoch 327/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2280 - accuracy: 0.5412 - val_loss: 1.4205 - val_accuracy: 0.5238\n",
      "Epoch 328/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2033 - accuracy: 0.5576 - val_loss: 1.4203 - val_accuracy: 0.5204\n",
      "Epoch 329/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2365 - accuracy: 0.5403 - val_loss: 1.4201 - val_accuracy: 0.5229\n",
      "Epoch 330/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2545 - accuracy: 0.5403 - val_loss: 1.4157 - val_accuracy: 0.5288\n",
      "Epoch 331/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2206 - accuracy: 0.5433 - val_loss: 1.4239 - val_accuracy: 0.5254\n",
      "Epoch 332/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2064 - accuracy: 0.5566 - val_loss: 1.4153 - val_accuracy: 0.5263\n",
      "Epoch 333/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2188 - accuracy: 0.5480 - val_loss: 1.4196 - val_accuracy: 0.5263\n",
      "Epoch 334/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2227 - accuracy: 0.5564 - val_loss: 1.4273 - val_accuracy: 0.5321\n",
      "Epoch 335/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2004 - accuracy: 0.5594 - val_loss: 1.4261 - val_accuracy: 0.5396\n",
      "Epoch 336/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2217 - accuracy: 0.5514 - val_loss: 1.4265 - val_accuracy: 0.5288\n",
      "Epoch 337/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2162 - accuracy: 0.5535 - val_loss: 1.4336 - val_accuracy: 0.5321\n",
      "Epoch 338/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2210 - accuracy: 0.5635 - val_loss: 1.4252 - val_accuracy: 0.5354\n",
      "Epoch 339/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2179 - accuracy: 0.5505 - val_loss: 1.4228 - val_accuracy: 0.5304\n",
      "Epoch 340/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2328 - accuracy: 0.5532 - val_loss: 1.4113 - val_accuracy: 0.5488\n",
      "Epoch 341/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2043 - accuracy: 0.5521 - val_loss: 1.4203 - val_accuracy: 0.5271\n",
      "Epoch 342/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1992 - accuracy: 0.5623 - val_loss: 1.4250 - val_accuracy: 0.5313\n",
      "Epoch 343/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1956 - accuracy: 0.5537 - val_loss: 1.4122 - val_accuracy: 0.5430\n",
      "Epoch 344/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.2127 - accuracy: 0.5623 - val_loss: 1.4125 - val_accuracy: 0.5396\n",
      "Epoch 345/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1957 - accuracy: 0.5530 - val_loss: 1.4209 - val_accuracy: 0.5388\n",
      "Epoch 346/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2041 - accuracy: 0.5546 - val_loss: 1.4263 - val_accuracy: 0.5321\n",
      "Epoch 347/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1902 - accuracy: 0.5630 - val_loss: 1.4126 - val_accuracy: 0.5421\n",
      "Epoch 348/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2087 - accuracy: 0.5614 - val_loss: 1.4176 - val_accuracy: 0.5396\n",
      "Epoch 349/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2105 - accuracy: 0.5653 - val_loss: 1.4079 - val_accuracy: 0.5354\n",
      "Epoch 350/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2032 - accuracy: 0.5508 - val_loss: 1.4158 - val_accuracy: 0.5371\n",
      "Epoch 351/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1889 - accuracy: 0.5546 - val_loss: 1.4194 - val_accuracy: 0.5363\n",
      "Epoch 352/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1911 - accuracy: 0.5548 - val_loss: 1.4185 - val_accuracy: 0.5338\n",
      "Epoch 353/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.2010 - accuracy: 0.5557 - val_loss: 1.4336 - val_accuracy: 0.5279\n",
      "Epoch 354/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1901 - accuracy: 0.5696 - val_loss: 1.4308 - val_accuracy: 0.5346\n",
      "Epoch 355/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1705 - accuracy: 0.5651 - val_loss: 1.4335 - val_accuracy: 0.5288\n",
      "Epoch 356/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1772 - accuracy: 0.5598 - val_loss: 1.4327 - val_accuracy: 0.5279\n",
      "Epoch 357/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1747 - accuracy: 0.5660 - val_loss: 1.4352 - val_accuracy: 0.5329\n",
      "Epoch 358/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1704 - accuracy: 0.5623 - val_loss: 1.4214 - val_accuracy: 0.5279\n",
      "Epoch 359/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1838 - accuracy: 0.5646 - val_loss: 1.4377 - val_accuracy: 0.5371\n",
      "Epoch 360/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1711 - accuracy: 0.5651 - val_loss: 1.4292 - val_accuracy: 0.5338\n",
      "Epoch 361/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1795 - accuracy: 0.5684 - val_loss: 1.4341 - val_accuracy: 0.5463\n",
      "Epoch 362/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1779 - accuracy: 0.5625 - val_loss: 1.4327 - val_accuracy: 0.5321\n",
      "Epoch 363/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1784 - accuracy: 0.5721 - val_loss: 1.4332 - val_accuracy: 0.5346\n",
      "Epoch 364/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1776 - accuracy: 0.5676 - val_loss: 1.4519 - val_accuracy: 0.5354\n",
      "Epoch 365/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1714 - accuracy: 0.5775 - val_loss: 1.4288 - val_accuracy: 0.5446\n",
      "Epoch 366/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1781 - accuracy: 0.5673 - val_loss: 1.4443 - val_accuracy: 0.5338\n",
      "Epoch 367/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1751 - accuracy: 0.5694 - val_loss: 1.4403 - val_accuracy: 0.5296\n",
      "Epoch 368/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1714 - accuracy: 0.5650 - val_loss: 1.4329 - val_accuracy: 0.5354\n",
      "Epoch 369/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1701 - accuracy: 0.5653 - val_loss: 1.4216 - val_accuracy: 0.5438\n",
      "Epoch 370/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1740 - accuracy: 0.5648 - val_loss: 1.4195 - val_accuracy: 0.5430\n",
      "Epoch 371/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1610 - accuracy: 0.5660 - val_loss: 1.4177 - val_accuracy: 0.5421\n",
      "Epoch 372/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1626 - accuracy: 0.5710 - val_loss: 1.4153 - val_accuracy: 0.5413\n",
      "Epoch 373/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1487 - accuracy: 0.5818 - val_loss: 1.4258 - val_accuracy: 0.5496\n",
      "Epoch 374/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1562 - accuracy: 0.5707 - val_loss: 1.4173 - val_accuracy: 0.5446\n",
      "Epoch 375/800\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.1626 - accuracy: 0.5719 - val_loss: 1.4297 - val_accuracy: 0.5388\n",
      "Epoch 376/800\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.1485 - accuracy: 0.5850 - val_loss: 1.4344 - val_accuracy: 0.5421\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "logs = Path() / \"my_logs\" / \"run_\" / \"Self\"\n",
    "checkpoint_filepath = \"my_checkpoints.Self.model.keras\"\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=logs)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=800, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4521 - accuracy: 0.5238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4520610570907593, 0.5237697958946228]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
