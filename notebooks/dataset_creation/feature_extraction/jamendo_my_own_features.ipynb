{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns() -> list:\n",
    "    \"\"\"\n",
    "    Zwraca listę kolumn, w tym ostatnia kolumna = 'genre'.\n",
    "    \"\"\"\n",
    "    # Przyjęte nazwy cech (według Twojej definicji):\n",
    "    feature_sizes = dict(\n",
    "        chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "        harmonic_separation=12, percussive_separation=12,\n",
    "        tempogram_ratio=13, mfcc=12, spectral_contrast=7,\n",
    "        tonnetz=6, poly_features=3, spectral_centroid=1,\n",
    "        spectral_bandwidth=1, spectral_flatness=1,\n",
    "        spectral_rolloff=1, rms=1, zcr=1, onset_strength=1,\n",
    "        plp=1, spectral_entropy=1, autocorelation=1,\n",
    "        pitch_features=1, tempo_variability=1,\n",
    "        spectral_decrease=1, dtempo=1\n",
    "    )\n",
    "    single_features = [\n",
    "        'tempo', 'beat_count', 'dtempo_changes', 'onset_count',\n",
    "        'low_energy_rate', 'harmonic_to_noise_rate', 'dynamic_range',\n",
    "        'swing_ratio', 'syncopation', 'roughness', 'warmth'\n",
    "    ]\n",
    "    moments = ('kurtosis','max','mean','median','min','skew','std','sum')\n",
    "    cols = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            # np. \"chroma_stft_00_mean\"...\n",
    "            it = (f\"{name}_{i:02d}_{moment}\" for i in range(size))\n",
    "            cols.extend(it)\n",
    "    cols = sorted(cols)\n",
    "    # Dodajemy single features\n",
    "    cols += single_features\n",
    "    # Dodajemy kolumnę 'genre'\n",
    "    cols.append('genre')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features_for_single_record(file_path:str) -> list:\n",
    "    y, sr = librosa.load(file_path)\n",
    "\n",
    "    # Chroma features\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=12)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr, n_chroma=12)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "\n",
    "    # MFCC, harmonic, Percusive\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=12)\n",
    "    harmonic, percussive = librosa.effects.hpss(y)\n",
    "    harmonic_separation = librosa.feature.mfcc(y=harmonic, sr=sr, n_mfcc=12)\n",
    "    percussive_separation = librosa.feature.mfcc(y=percussive, sr=sr, n_mfcc=12)\n",
    "\n",
    "    # Tempogram\n",
    "    tempogram = librosa.feature.tempogram(y=y, sr=sr)\n",
    "    tempogram_ratio = librosa.feature.tempogram_ratio(tg=tempogram, sr=sr)\n",
    "\n",
    "    # Tonnetz\n",
    "    tonnetz = librosa.feature.tonnetz(y=harmonic, sr=sr)\n",
    "\n",
    "    # Poly features\n",
    "    poly_features = librosa.feature.poly_features(y=y, sr=sr, order=2)\n",
    "\n",
    "    # Spectral\n",
    "    def calculate_spectral_entropy(y, sr):\n",
    "        psd = np.abs(librosa.stft(y)) ** 2\n",
    "        psd_sum = np.sum(psd)\n",
    "        if psd_sum == 0:\n",
    "            psd_norm = psd\n",
    "        else:\n",
    "            psd_norm = psd / (psd_sum + 1e-10)\n",
    "        entropy = -np.sum(psd_norm * np.log2(psd_norm + 1e-10), axis=0)\n",
    "        return entropy\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spectral_entropy = calculate_spectral_entropy(y, sr)\n",
    "\n",
    "    # RMS\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    \n",
    "    # ZCR\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    \n",
    "    # Onset strength\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    # plp\n",
    "    plp = librosa.beat.plp(onset_envelope=onset_env, sr=sr)\n",
    "\n",
    "    # Autocorrelation\n",
    "    autocorrelation = librosa.autocorrelate(y)\n",
    "\n",
    "    # Pitch features\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitch_features = pitches[pitches > 0]\n",
    "\n",
    "    # Tempo variability\n",
    "    tempo_variability = librosa.feature.rhythm.tempo(onset_envelope=onset_env, sr=sr, aggregate=None)\n",
    "\n",
    "    # Spectral decrease\n",
    "    def calculate_spectral_decrease(y, sr):\n",
    "        S = np.abs(librosa.stft(y))\n",
    "        decrease = np.mean(np.diff(S, axis=0), axis=1)\n",
    "        return decrease\n",
    "    spectral_decrease = calculate_spectral_decrease(y, sr)\n",
    "\n",
    "    # Dynamic tempo\n",
    "    dtempo = librosa.feature.tempo(onset_envelope=onset_env, sr=sr, aggregate=None)\n",
    "    \n",
    "\n",
    "    # Single features\n",
    "    def count_value_changes(arr:list) -> int:\n",
    "        changes = 0\n",
    "        for i in range(1, len(arr)):\n",
    "            if arr[i] != arr[i - 1]:\n",
    "                changes += 1\n",
    "        return changes\n",
    "\n",
    "    def calculate_swing_ratio(y, sr):\n",
    "        onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "        onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "        swing_ratios = []\n",
    "        for i in range(1, len(onset_times)-1, 2):\n",
    "            duration_1 = onset_times[i] - onset_times[i-1]\n",
    "            duration_2 = onset_times[i+1] - onset_times[i]\n",
    "            if duration_2 != 0:\n",
    "                swing_ratio = duration_1 / duration_2\n",
    "                swing_ratios.append(swing_ratio)\n",
    "        return np.mean(swing_ratios) if swing_ratios else 0\n",
    "    \n",
    "    def calculate_syncopation(beats, sr):\n",
    "        onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "        onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "        beat_times = librosa.frames_to_time(beats, sr=sr)\n",
    "        syncopation = 0\n",
    "        for onset in onset_times:\n",
    "            closest_beat = min(beat_times, key=lambda x: abs(x - onset))\n",
    "            syncopation += abs(onset - closest_beat)\n",
    "        return syncopation / len(onset_times) if len(onset_times) else 0\n",
    "    \n",
    "    def calculate_roughness(harmonic, sr):\n",
    "        S = np.abs(librosa.stft(harmonic))\n",
    "        frequencies = librosa.fft_frequencies(sr=sr)\n",
    "        magnitudes = np.mean(S, axis=1)\n",
    "        roughness = 0\n",
    "        for i in range(len(frequencies) - 1):\n",
    "            for j in range(i + 1, len(frequencies)):\n",
    "                if abs(frequencies[i] - frequencies[j]) < 20:\n",
    "                    roughness += magnitudes[i] * magnitudes[j] / abs(frequencies[i] - frequencies[j])\n",
    "        return roughness\n",
    "    \n",
    "    def calculate_warmth(y, sr):\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        low_freq_idx = np.where(librosa.mel_frequencies(n_mels=128, fmax=sr/2) < 200)[0]\n",
    "        low_freq_mean = np.mean(S_db[low_freq_idx, :])\n",
    "        overall_mean = np.mean(S_db)\n",
    "        if overall_mean == 0:\n",
    "            return 0\n",
    "        warmth = low_freq_mean / (overall_mean + 1e-10)\n",
    "        return warmth\n",
    "\n",
    "    dtempo_changes = count_value_changes(dtempo)\n",
    "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    beat_count = len(beats)\n",
    "    onset_count = len(librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr))\n",
    "    low_energy = np.sum(rms < 0.5 * np.mean(rms)) / len(rms)\n",
    "\n",
    "    def calculate_harmonic_ratio(harmonic, percussive):\n",
    "        harmonic_sum = np.sum(harmonic)\n",
    "        percussive_sum = np.sum(percussive)\n",
    "        denominator = percussive_sum + harmonic_sum\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        harmonic_ratio = harmonic_sum / denominator\n",
    "        return harmonic_ratio\n",
    "        \n",
    "    harmonic_ratio = calculate_harmonic_ratio(harmonic, percussive)\n",
    "    dynamic_range = np.max(rms) - np.min(rms)\n",
    "    swing_ratio = calculate_swing_ratio(y, sr)\n",
    "    syncopation = calculate_syncopation(beats, sr)\n",
    "    roughness = calculate_roughness(harmonic, sr)\n",
    "    warmth = calculate_warmth(y, sr)\n",
    "\n",
    "    moments = ['kurtosis', 'max', 'mean', 'median', 'min', 'skew', 'std', 'sum']\n",
    "\n",
    "    def aggregate_feature(feature):\n",
    "        if np.allclose(feature, feature[0]):\n",
    "            return [np.nan, np.max(feature), np.mean(feature), np.median(feature), \n",
    "                np.min(feature), np.std(feature), np.nan, sum(feature)]\n",
    "        else:\n",
    "            return [scipy.stats.kurtosis(feature), np.max(feature), np.mean(feature), np.median(feature), \n",
    "                    np.min(feature), np.std(feature), scipy.stats.skew(feature), sum(feature)]\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for f in [autocorrelation, chroma_cens, chroma_cqt, chroma_stft, dtempo, harmonic_separation,\n",
    "              mfcc, onset_env, percussive_separation, pitch_features, plp, poly_features, \n",
    "              rms, spectral_bandwidth, spectral_centroid, spectral_contrast, spectral_decrease, \n",
    "              spectral_entropy, spectral_flatness, spectral_rolloff, tempo_variability, \n",
    "              tempogram_ratio, tonnetz, zcr]:\n",
    "        if f.ndim == 1:\n",
    "            features.extend(aggregate_feature(f))\n",
    "        else:\n",
    "            features.extend(np.hstack([aggregate_feature(f[i]) for i in range(f.shape[0])]))\n",
    "    \n",
    "    single_features = [tempo[0], beat_count, dtempo_changes, onset_count, low_energy, harmonic_ratio,\n",
    "                       dynamic_range, swing_ratio, syncopation, roughness, warmth]\n",
    "    features.extend(single_features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata_map(metadata_csv: str) -> dict:\n",
    "    \"\"\"\n",
    "    Wczytuje plik z metadanymi chunków (zawierający PATH i GENRE),\n",
    "    Zwraca słownik: relatywna_sciezka -> gatunek\n",
    "    Zakładamy, że w pliku CSV jest kolumna 'PATH' oraz 'GENRE'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    # np. PATH = \"train/Rock/123_chunk_0.mp3\"\n",
    "    # GENRE = \"Rock\"\n",
    "    # W zależności od nazewnictwa w Twoim pliku, zmień np. \"Genre\" -> \"GENRE\"\n",
    "    \n",
    "    if 'PATH' not in df.columns:\n",
    "        raise ValueError(\"Brak kolumny 'PATH' w metadata CSV.\")\n",
    "    if 'TAGS' not in df.columns:\n",
    "        raise ValueError(\"Brak kolumny 'TAGS' w metadata CSV.\")\n",
    "    \n",
    "    path_to_genre = {}\n",
    "    for _, row in df.iterrows():\n",
    "        rel_path = row['PATH']\n",
    "        g = row['TAGS']  # lub cokolwiek innego, np. row['TAGS']\n",
    "        path_to_genre[rel_path] = g\n",
    "    return path_to_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path: str, base_folder: str, path_to_genre_map: dict) -> list:\n",
    "    \"\"\"\n",
    "    Oblicza cechy (calculate_features_for_single_record), a następnie\n",
    "    dołącza 'genre' na końcu, zaczerpnięty z path_to_genre_map.\n",
    "    \n",
    "    :param file_path: pełna ścieżka do pliku MP3 (np. \".../train/Rock/123.mp3\")\n",
    "    :param base_folder: folder bazowy (np. \".../split_audio_dataset/\") \n",
    "                        aby wyliczyć ścieżkę relatywną do mapy.\n",
    "    :param path_to_genre_map: dict: rel_path -> genre\n",
    "    :return: list cech + [genre], lub None w razie błędu\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obliczamy cechy audio\n",
    "        features = calculate_features_for_single_record(file_path)\n",
    "        \n",
    "        # Wyznaczamy ścieżkę relatywną względem base_folder,\n",
    "        # bo w metadata CSV pewnie jest PATH relatywna do base_folder\n",
    "        rel_path = os.path.relpath(file_path, base_folder).replace(\"\\\\\",\"/\")\n",
    "        \n",
    "        # Pobieramy gatunek z mapy\n",
    "        genre = path_to_genre_map.get(rel_path, \"Unknown\")\n",
    "        \n",
    "        # Dodajemy go jako OSTATNI element listy\n",
    "        features.append(genre)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"[BŁĄD] Podczas przetwarzania pliku {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_files_in_parallel(folder: str, path_to_genre_map: dict) -> list:\n",
    "    \"\"\"\n",
    "    Wyszukuje pliki .mp3 w folderze (rekurencyjnie),\n",
    "    wywołuje process_file w wątkach, dołączając 'genre' z path_to_genre_map.\n",
    "    Zwraca listę wierszy (list cech).\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    mp3_paths = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.lower().endswith('.mp3'):\n",
    "                mp3_paths.append(os.path.join(root, f))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        future_tasks = {\n",
    "            executor.submit(process_file, p, folder, path_to_genre_map): p for p in mp3_paths\n",
    "        }\n",
    "        for future in tqdm(\n",
    "            concurrent.futures.as_completed(future_tasks),\n",
    "            total=len(future_tasks),\n",
    "            desc=f\"Przetwarzanie plików w {folder}\",\n",
    "            unit=\"plik\"\n",
    "        ):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                all_features.append(result)\n",
    "\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_as_csv(\n",
    "    base_folder: str,\n",
    "    metadata_csv: str,\n",
    "    output_csv: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    1) Tworzymy mapę: relatywna_ścieżka -> gatunek (z pliku metadata_csv).\n",
    "    2) Przetwarzamy wszystkie mp3 w base_folder,\n",
    "       obliczamy cechy + dołączamy gatunek z mapy,\n",
    "       zapisujemy do output_csv.\n",
    "    \"\"\"\n",
    "    # Budujemy mapę PATH->GENRE\n",
    "    path_to_genre_map = build_metadata_map(metadata_csv)\n",
    "    # print(path_to_genre_map)\n",
    "    # print(len(path_to_genre_map))\n",
    "    \n",
    "    # Obliczamy cechy w wątkach\n",
    "    rows = process_files_in_parallel(base_folder, path_to_genre_map)\n",
    "    \n",
    "    # Budujemy DataFrame i zapisujemy\n",
    "    df = pd.DataFrame(rows, columns=columns())\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[INFO] Zapisano cechy do pliku {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/val/:   0%|          | 0/5982 [00:00<?, ?plik/s]c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=384 is too large for input signal of length=364\n",
      "  warnings.warn(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/val/:  33%|███▎      | 1952/5982 [32:39<1:07:43,  1.01s/plik]c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/val/: 100%|██████████| 5982/5982 [1:27:01<00:00,  1.15plik/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Zapisano cechy do pliku val_features.csv\n"
     ]
    }
   ],
   "source": [
    "val_folder    = \"../../../datasets/jamendo/split_audio_dataset/val/\"\n",
    "val_metadata  = \"../../../datasets/jamendo/metadata/val_metadata.csv\"\n",
    "val_features_csv = \"val_features.csv\"\n",
    "\n",
    "create_features_as_csv(\n",
    "    base_folder=val_folder,\n",
    "    metadata_csv=val_metadata,\n",
    "    output_csv=val_features_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/:   0%|          | 0/6372 [00:00<?, ?plik/s]c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=384 is too large for input signal of length=364\n",
      "  warnings.warn(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/:  21%|██▏       | 1363/6372 [15:29<38:06,  2.19plik/s]  c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/:  74%|███████▍  | 4736/6372 [58:06<38:10,  1.40s/plik]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_10.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/:  74%|███████▍  | 4738/6372 [58:06<23:22,  1.17plik/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_16.mp3: index 0 is out of bounds for axis 0 with size 0\n",
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_14.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/:  74%|███████▍  | 4739/6372 [58:07<18:18,  1.49plik/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_13.mp3: index 0 is out of bounds for axis 0 with size 0\n",
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_12.mp3: index 0 is out of bounds for axis 0 with size 0\n",
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_15.mp3: index 0 is out of bounds for axis 0 with size 0\n",
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/test/76\\10376_chunk_11.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/test/: 100%|██████████| 6372/6372 [1:20:27<00:00,  1.32plik/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Zapisano cechy do pliku test_features.csv\n"
     ]
    }
   ],
   "source": [
    "test_folder    = \"../../../datasets/jamendo/split_audio_dataset/test/\"\n",
    "test_metadata  = \"../../../datasets/jamendo/metadata/test_metadata.csv\"\n",
    "test_features_csv = \"test_features.csv\"\n",
    "\n",
    "create_features_as_csv(\n",
    "    base_folder=test_folder,\n",
    "    metadata_csv=test_metadata,\n",
    "    output_csv=test_features_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:   0%|          | 0/26743 [00:00<?, ?plik/s]c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=384 is too large for input signal of length=364\n",
      "  warnings.warn(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:   5%|▌         | 1349/26743 [16:41<5:28:07,  1.29plik/s] c:\\Users\\szyme\\Documents\\Praca_Magisterska\\Musical-Genres-Classification\\.venv\\musical_genres\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:   5%|▌         | 1365/26743 [16:55<4:03:03,  1.74plik/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/train/04\\433604_chunk_31.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:   7%|▋         | 1763/26743 [22:54<5:24:40,  1.28plik/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/train/06\\12306_chunk_11.mp3: index 0 is out of bounds for axis 0 with size 0\n",
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/train/06\\12306_chunk_12.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:   7%|▋         | 1766/26743 [22:55<3:45:33,  1.85plik/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/train/06\\12306_chunk_13.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/:  84%|████████▍ | 22506/26743 [4:46:42<1:36:31,  1.37s/plik]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BŁĄD] Podczas przetwarzania pliku ../../../datasets/jamendo/split_audio_dataset/train/82\\433582_chunk_31.mp3: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie plików w ../../../datasets/jamendo/split_audio_dataset/train/: 100%|██████████| 26743/26743 [5:57:51<00:00,  1.25plik/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Zapisano cechy do pliku train_features.csv\n"
     ]
    }
   ],
   "source": [
    "train_folder    = \"../../../datasets/jamendo/split_audio_dataset/train/\"\n",
    "train_metadata  = \"../../../datasets/jamendo/metadata/train_metadata.csv\"\n",
    "train_features_csv = \"train_features.csv\"\n",
    "\n",
    "create_features_as_csv(\n",
    "    base_folder=train_folder,\n",
    "    metadata_csv=train_metadata,\n",
    "    output_csv=train_features_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
