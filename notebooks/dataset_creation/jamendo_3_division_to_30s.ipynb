{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division reduced dataset to 30 seconds mp3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing audio files into 30-second files, removing silence, creating metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_track(row, audio_folder, output_folder, top_db=30, chunk_duration_sec=30):\n",
    "    \"\"\"\n",
    "    Przetwarza jedną piosenkę (jeden wiersz metadanych):\n",
    "      - Wczytuje plik audio (z audio_folder + row[\"PATH\"])\n",
    "      - Usuwa ciszę z początku i końca (librosa.effects.trim)\n",
    "      - Dzieli audio na chunki 30 sek.\n",
    "      - Każdy chunk zapisuje do MP3 w subfolderze output_folder\n",
    "      - Zwraca listę słowników z metadanymi chunków,\n",
    "        gdzie PATH = np. \"57/1294657_chunk_0.mp3\" (relatywnie do output_folder).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    track_id = row[\"TRACK_ID\"]\n",
    "    artist_id = row[\"ARTIST_ID\"]\n",
    "    album_id  = row[\"ALBUM_ID\"]\n",
    "\n",
    "    # Ścieżka do oryginalnego pliku audio\n",
    "    # (zakładamy, że w metadanych 'PATH' jest relatywna ścieżka do audio_folder)\n",
    "    audio_path = os.path.join(audio_folder, row[\"PATH\"])\n",
    "\n",
    "    try:\n",
    "        # 1. Wczytaj audio\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        # 2. Trim ciszy z początku i końca\n",
    "        audio_trimmed, trimmed_indices = librosa.effects.trim(audio, top_db=top_db)\n",
    "        start_trim, _ = trimmed_indices\n",
    "        \n",
    "        # 3. Oblicz liczbę chunków 30 sek (pomijamy końcówkę < 30s)\n",
    "        chunk_length = chunk_duration_sec * sr\n",
    "        total_samples = len(audio_trimmed)\n",
    "        num_full_chunks = total_samples // chunk_length\n",
    "        \n",
    "        # 4. Podfolder docelowy wg 2 ostatnich cyfr track_id (np. \"57\")\n",
    "        subfolder_name = str(track_id)[-2:].zfill(2)\n",
    "        \n",
    "        # 5. Iteracja po chunkach\n",
    "        for i in range(num_full_chunks):\n",
    "            start_idx = i * chunk_length\n",
    "            end_idx   = start_idx + chunk_length\n",
    "            chunk     = audio_trimmed[start_idx:end_idx]\n",
    "            \n",
    "            chunk_start_sec = (start_trim + start_idx) / sr\n",
    "            chunk_end_sec   = (start_trim + end_idx)   / sr\n",
    "            \n",
    "            # Nazwa pliku MP3, np. \"1294657_chunk_0.mp3\"\n",
    "            new_filename = f\"{track_id}_chunk_{i}.mp3\"\n",
    "            \n",
    "            # Relatywna ścieżka, np. \"57/1294657_chunk_0.mp3\"\n",
    "            # Uwaga: używamy slash '/' by była ta sama na każdym OS.\n",
    "            rel_path = f\"{subfolder_name}/{new_filename}\"\n",
    "            \n",
    "            # Ścieżka docelowa na dysku (output_folder + rel_path)\n",
    "            dest_path = os.path.join(output_folder, subfolder_name, new_filename)\n",
    "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            \n",
    "            # 6. Konwersja -> int16 -> AudioSegment -> zapis MP3\n",
    "            samples_int16 = (chunk * 32767).astype(np.int16)\n",
    "            audio_segment = AudioSegment(\n",
    "                samples_int16.tobytes(),\n",
    "                frame_rate=sr,\n",
    "                sample_width=2,\n",
    "                channels=1\n",
    "            )\n",
    "            audio_segment.export(dest_path, format=\"mp3\")\n",
    "            \n",
    "            # 7. Dodaj metadane chunku\n",
    "            results.append({\n",
    "                \"CHUNK_ID\": f\"{track_id}_chunk_{i}\",\n",
    "                \"TRACK_ID\": track_id,\n",
    "                \"ARTIST_ID\": artist_id,\n",
    "                \"ALBUM_ID\": album_id,\n",
    "                \"PATH\": rel_path,  # <--- TYLKO np. \"57/1294657_chunk_0.mp3\"\n",
    "                \"START_SEC\": chunk_start_sec,\n",
    "                \"END_SEC\": chunk_end_sec,\n",
    "                \"CHUNK_DURATION\": chunk_duration_sec,\n",
    "                \"TAGS\": row[\"TAGS\"],\n",
    "                \"GENRE_LIST\": row[\"genre_list\"],\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[BŁĄD w process_track] {audio_path}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def parallel_chunking_with_threads(\n",
    "    metadata_csv,\n",
    "    audio_folder,\n",
    "    output_folder,\n",
    "    output_metadata,\n",
    "    top_db=30,\n",
    "    chunk_duration_sec=30,\n",
    "    max_workers=4\n",
    "):\n",
    "    \"\"\"\n",
    "    Równoległe przetwarzanie utworów z pliku CSV w wątkach:\n",
    "     - Każdy wiersz = 1 plik audio do pocięcia\n",
    "     - Zbiera metadane chunków i zapisuje do pliku CSV\n",
    "     - Ścieżki chunków (PATH) zapisywane są RELATYWNIE,\n",
    "       np. \"57/1294657_chunk_0.mp3\".\n",
    "    \"\"\"\n",
    "    \n",
    "    import concurrent.futures\n",
    "    \n",
    "    # 1. Wczytanie metadanych\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    \n",
    "    # Sprawdź, czy mamy wymagane kolumny\n",
    "    required_cols = [\"TRACK_ID\", \"PATH\", \"TAGS\", \"genre_list\", \"ARTIST_ID\", \"ALBUM_ID\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Brak wymaganej kolumny '{col}' w pliku {metadata_csv}.\")\n",
    "    \n",
    "    # 2. Tworzymy docelowy folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 3. Uruchamiamy ThreadPoolExecutor\n",
    "    futures = []\n",
    "    new_metadata = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for row_tuple in df.itertuples(index=False):\n",
    "            row_dict = row_tuple._asdict()\n",
    "            future = executor.submit(\n",
    "                process_track,\n",
    "                row=row_dict,\n",
    "                audio_folder=audio_folder,\n",
    "                output_folder=output_folder,\n",
    "                top_db=top_db,\n",
    "                chunk_duration_sec=chunk_duration_sec\n",
    "            )\n",
    "            futures.append(future)\n",
    "        \n",
    "        # 4. Odbieramy wyniki i aktualizujemy pasek postępu\n",
    "        for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "            result = f.result()\n",
    "            new_metadata.extend(result)\n",
    "    \n",
    "    # 5. Tworzymy finalny DataFrame i zapisujemy do CSV\n",
    "    final_df = pd.DataFrame(new_metadata)\n",
    "    final_df.to_csv(output_metadata, index=False)\n",
    "    \n",
    "    print(f\"\\nZapisano CSV z chunkami: {output_metadata}\")\n",
    "    print(f\"Liczba chunków: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 5561/5561 [48:56<00:00,  1.89it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zapisano CSV z chunkami: ../../datasets/jamendo/metadata/audio_30_s_chunks_metadata.csv\n",
      "Liczba chunków: 39097\n"
     ]
    }
   ],
   "source": [
    "metadata_csv    = \"../../datasets/jamendo/metadata/reduced_audio_dataset_15_genres.csv\"\n",
    "audio_folder    = \"../../datasets/jamendo/original_audio/\"\n",
    "output_folder   = \"../../datasets/jamendo/audio_30_s_chunks/\"\n",
    "output_metadata = \"../../datasets/jamendo/metadata/audio_30_s_chunks_metadata.csv\"\n",
    "\n",
    "parallel_chunking_with_threads(\n",
    "    metadata_csv=metadata_csv,\n",
    "    audio_folder=audio_folder,\n",
    "    output_folder=output_folder,\n",
    "    output_metadata=output_metadata,\n",
    "    top_db=30,            # docinanie ciszy\n",
    "    chunk_duration_sec=30,\n",
    "    max_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing dataset for equal occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba plików (chunków) w '../../datasets/jamendo/audio_30_s_chunks/': 39097\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1. Funkcja do zliczania wszystkich plików w danym folderze\n",
    "#    (łącznie z plikami w podfolderach)\n",
    "# -------------------------------------------\n",
    "def count_files_in_directory(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # można dodatkowo filtrować np. czy plik ma rozszerzenie .mp3\n",
    "            # if file.endswith('.mp3'):\n",
    "            #     count += 1\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# -------------------------------------------\n",
    "# PRZYKŁAD UŻYCIA: zliczanie wszystkich chunków (plików) w folderze\n",
    "# -------------------------------------------\n",
    "directory_path = \"../../datasets/jamendo/audio_30_s_chunks/\"\n",
    "file_count = count_files_in_directory(directory_path)\n",
    "print(f\"Liczba plików (chunków) w '{directory_path}': {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of genre occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zestawienie liczby chunków wg gatunku i rodzaju (Single/Multiple):\n",
      "genre_type   Multiple  Single\n",
      "TAGS                         \n",
      "Ambient          1834    2285\n",
      "Blues             681    1736\n",
      "Elektronika      3330    2290\n",
      "Folk             1374    1920\n",
      "Funk             1264    1947\n",
      "Hip-Hop           735    2130\n",
      "House             957    3000\n",
      "Jazz             1393    2366\n",
      "Klasyczna         995    2285\n",
      "Latin             637    1115\n",
      "Metal             406    3354\n",
      "Pop              2582     875\n",
      "Reggae            329    3210\n",
      "Rock             2144    1305\n",
      "Techno           1727       0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 2. Wczytanie metadanych chunków\n",
    "#    Zakładamy, że mamy kolumnę \"TAGS\" z listą gatunków w formacie \"Rock;Pop\"\n",
    "# -------------------------------------------\n",
    "df = pd.read_csv(\"../../datasets/jamendo/metadata/audio_30_s_chunks_metadata.csv\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3. Rozbicie kolumny TAGS i obliczenie single/multiple\n",
    "# -------------------------------------------\n",
    "# Jeśli kolumna z gatunkami nazywa się inaczej (np. \"tags\"), dostosuj poniższy kod.\n",
    "df[\"TAGS\"] = df[\"TAGS\"].astype(str).str.split(';')\n",
    "\n",
    "# Dodajemy kolumnę z liczbą gatunków\n",
    "df[\"genre_count\"] = df[\"TAGS\"].apply(len)\n",
    "\n",
    "# Rozbijamy wiersze tak, by każdy gatunek był w osobnym wierszu\n",
    "df_expanded = df.explode(\"TAGS\")\n",
    "\n",
    "# Tworzymy kolumnę 'genre_type' informującą, czy chunk ma 1 gatunek czy wiele\n",
    "df_expanded[\"genre_type\"] = df_expanded[\"genre_count\"].apply(lambda x: \"Single\" if x == 1 else \"Multiple\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 4. Grupowanie wg gatunku i rodzaju\n",
    "# -------------------------------------------\n",
    "genre_breakdown = df_expanded.groupby([\"TAGS\", \"genre_type\"]).size().unstack(fill_value=0)\n",
    "\n",
    "print(\"\\nZestawienie liczby chunków wg gatunku i rodzaju (Single/Multiple):\")\n",
    "print(genre_breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
