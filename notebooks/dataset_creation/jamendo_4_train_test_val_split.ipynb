{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train, test and valid subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_and_files(\n",
    "    metadata_path: str,\n",
    "    audio_folder: str,\n",
    "    output_folder: str,\n",
    "    train_ratio: float = 0.7,\n",
    "    val_ratio: float   = 0.15,\n",
    "    test_ratio: float  = 0.15\n",
    "):\n",
    "    \"\"\"\n",
    "    Dzieli zbiór chunków (audio_30_s_chunks_metadata) na train/val/test\n",
    "    w proporcjach 70-15-15 (domyślnie), tak aby pary (ARTIST_ID, ALBUM_ID)\n",
    "    trafiały do jednego zbioru.\n",
    "    \n",
    "    Następnie tworzy:\n",
    "      - train_metadata.csv, val_metadata.csv, test_metadata.csv\n",
    "        (bez zmiany PATH - wciąż np. \"76/1371076_chunk_0.mp3\")\n",
    "      - kopiuje pliki MP3 do:\n",
    "          output_folder/train/...,\n",
    "          output_folder/val/...,\n",
    "          output_folder/test/...,\n",
    "        zachowując oryginalną strukturę podfolderów (np. \"76/\").\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Wczytujemy metadane\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "    # Sprawdzamy czy sumy proporcji = 1.0\n",
    "    if not np.isclose(train_ratio + val_ratio + test_ratio, 1.0):\n",
    "        raise ValueError(\"Proporcje zbiorów (train_ratio, val_ratio, test_ratio) muszą sumować się do 1.0.\")\n",
    "\n",
    "    # Upewniamy się, że istnieją kolumny: ARTIST_ID, ALBUM_ID, PATH\n",
    "    required_cols = [\"ARTIST_ID\", \"ALBUM_ID\", \"PATH\"]\n",
    "    for col in required_cols:\n",
    "        if col not in metadata.columns:\n",
    "            raise ValueError(f\"Brak wymaganej kolumny '{col}' w pliku {metadata_path}.\")\n",
    "\n",
    "    # 2. Grupujemy po (ARTIST_ID, ALBUM_ID)\n",
    "    group_keys = list(metadata.groupby([\"ARTIST_ID\", \"ALBUM_ID\"]).groups.keys())  # lista par (artist, album)\n",
    "\n",
    "    # 3. Tasujemy i dzielimy listę grup w stosunku 70-15-15\n",
    "    np.random.shuffle(group_keys)\n",
    "    n = len(group_keys)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end   = train_end + int(n * val_ratio)\n",
    "\n",
    "    train_keys = set(group_keys[:train_end])\n",
    "    val_keys   = set(group_keys[train_end:val_end])\n",
    "    test_keys  = set(group_keys[val_end:])\n",
    "\n",
    "    # 4. Przypisujemy subset (train/val/test) na podstawie par (ARTIST_ID, ALBUM_ID)\n",
    "    def assign_subset(row):\n",
    "        key = (row[\"ARTIST_ID\"], row[\"ALBUM_ID\"])\n",
    "        if key in train_keys:\n",
    "            return \"train\"\n",
    "        elif key in val_keys:\n",
    "            return \"val\"\n",
    "        elif key in test_keys:\n",
    "            return \"test\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    metadata[\"subset\"] = metadata.apply(assign_subset, axis=1)\n",
    "\n",
    "    # Dzielimy na 3 DataFrame\n",
    "    train_data = metadata[metadata[\"subset\"] == \"train\"].copy()\n",
    "    val_data   = metadata[metadata[\"subset\"] == \"val\"].copy()\n",
    "    test_data  = metadata[metadata[\"subset\"] == \"test\"].copy()\n",
    "\n",
    "    # Sprawdzamy czy sumy się zgadzają\n",
    "    assert len(train_data) + len(val_data) + len(test_data) == len(metadata), \\\n",
    "        \"Suma (train + val + test) nie zgadza się z całkowitą liczbą chunków!\"\n",
    "\n",
    "    # 5. Tworzymy foldery docelowe (train, val, test)\n",
    "    os.makedirs(os.path.join(output_folder, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, \"val\"),   exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, \"test\"),  exist_ok=True)\n",
    "\n",
    "    # 6. Funkcja do kopiowania plików z tqdm\n",
    "    def copy_files(df_subset, subset_name):\n",
    "        \"\"\"\n",
    "        Kopiuje pliki z audio_folder + PATH -> output_folder/subset_name + PATH\n",
    "        zachowując strukturę (np. \"76/1371076_chunk_0.mp3\").\n",
    "        Nie modyfikuje kolumny PATH w df_subset.\n",
    "        \"\"\"\n",
    "        subset_folder = os.path.join(output_folder, subset_name)\n",
    "        \n",
    "        # Pasek postępu\n",
    "        for _, row_ in tqdm(df_subset.iterrows(),\n",
    "                            total=len(df_subset),\n",
    "                            desc=f\"Kopiowanie do {subset_name}\",\n",
    "                            unit=\"plik\"):\n",
    "            rel_path = row_[\"PATH\"]  # np. \"76/1371076_chunk_0.mp3\"\n",
    "            src  = os.path.join(audio_folder, rel_path)\n",
    "            dest = os.path.join(subset_folder, rel_path)\n",
    "\n",
    "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dest)\n",
    "            else:\n",
    "                print(f\"[WARNING] Brak pliku: {src}\")\n",
    "\n",
    "    print(\"\\nRozpoczynam kopiowanie plików do train/val/test...\")\n",
    "\n",
    "    # Kopiujemy pliki do poszczególnych folderów\n",
    "    copy_files(train_data, \"train\")\n",
    "    copy_files(val_data,   \"val\")\n",
    "    copy_files(test_data,  \"test\")\n",
    "\n",
    "    # 7. Zwracamy lub zapisujemy zbiory w postaci CSV\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam kopiowanie plików do train/val/test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kopiowanie do train: 100%|██████████| 26743/26743 [00:31<00:00, 844.08plik/s]\n",
      "Kopiowanie do val: 100%|██████████| 5982/5982 [00:07<00:00, 794.24plik/s]\n",
      "Kopiowanie do test: 100%|██████████| 6372/6372 [00:08<00:00, 715.29plik/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zbiory danych i pliki audio zostały podzielone i zapisane.\n",
      "- Zbiór treningowy: 26743 przykładów\n",
      "- Zbiór walidacyjny: 5982 przykładów\n",
      "- Zbiór testowy:    6372 przykładów\n"
     ]
    }
   ],
   "source": [
    "metadata_path = \"../../datasets/jamendo/metadata/audio_30_s_chunks_metadata.csv\"\n",
    "audio_folder  = \"../../datasets/jamendo/audio_30_s_chunks/\"\n",
    "output_folder = \"../../datasets/jamendo/split_audio_dataset/\"\n",
    "\n",
    "# Wywołujemy podział\n",
    "train_data, val_data, test_data = split_dataset_and_files(\n",
    "    metadata_path,\n",
    "    audio_folder,\n",
    "    output_folder,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15\n",
    ")\n",
    "\n",
    "# Zapis do plików CSV\n",
    "train_data.to_csv(\"../../datasets/jamendo/metadata/train_metadata.csv\", index=False)\n",
    "val_data.to_csv(\"../../datasets/jamendo/metadata/val_metadata.csv\",   index=False)\n",
    "test_data.to_csv(\"../../datasets/jamendo/metadata/test_metadata.csv\", index=False)\n",
    "\n",
    "print(\"\\nZbiory danych i pliki audio zostały podzielone i zapisane.\")\n",
    "print(f\"- Zbiór treningowy: {len(train_data)} przykładów\")\n",
    "print(f\"- Zbiór walidacyjny: {len(val_data)} przykładów\")\n",
    "print(f\"- Zbiór testowy:    {len(test_data)} przykładów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
